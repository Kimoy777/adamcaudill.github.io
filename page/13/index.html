
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Adam Caudill</title>
  <meta name="author" content="Adam Caudill">

  
  <meta name="description" content="I&#8217;ve released a new version of CCSRCH, the open-source PAN (a.k.a credit card number) search tool to help companies maintain PCI compliance. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://adamcaudill.com//page/13">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Adam Caudill" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-106942-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Adam Caudill</a></h1>
  
    <h2>Independent Security Researcher &amp; Software Developer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:adamcaudill.com/" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/archives/">Archives</a></li>
  <li><a href="/speaking/">Speaking</a></li>
  <li><a href="/about/">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/02/29/ccsrch-v1-0-7/">CCSRCH v1.0.7</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-02-29T23:47:17-05:00" pubdate data-updated="true">Feb 29<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I&#8217;ve released a new version of <a href="https://github.com/adamcaudill/ccsrch">CCSRCH</a>, the open-source PAN (a.k.a credit card number) search tool to help companies maintain PCI compliance. This is a fairly minor release, primarily focusing on reducing false positives. The scanner has been updated to exclude the following:</p>

<ul>
<li><p>Results made up of the same two digits repeating (i.e. 5454545454545454).</p></li>
<li><p>Results that have seven or more of the same digits repeating (i.e. 5555555555554444).</p></li>
</ul>


<p>I also fixed a bug that I introduced in v1.0.6 that prevented it from compiling on certain *nix systems; while I was in there I also fixed several instances of this building warning on newer Linux distros:</p>

<pre><code>warning: call to __builtin___strncat_chk might overflow destination buffer
 [enabled by default]
</code></pre>

<p>I also took the time to write-up really simple build instructions for *nix users:</p>

<pre><code>$ wget -O ccsrch.tar.gz https://github.com/adamcaudill/ccsrch/tarball/master
$ tar -xvzf ccsrch.tar.gz
$ cd adamcaudill-ccsrch-&lt;rev&gt;/
$ make all
</code></pre>

<p>This will probably be the last release for now unless a bug turns up; to improve results further I&#8217;m working on a new project (<a href="https://github.com/adamcaudill/ccsrch-score">ccsrch-score</a>), hopefully it&#8217;ll be released soon.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/01/26/iin-bin-database/">IIN (BIN) Database</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-26T12:58:28-05:00" pubdate data-updated="true">Jan 26<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>An <a href="http://en.wikipedia.org/wiki/ISO/IEC_7812">Issuer Identification Number</a> (IIN, more commonly called a BIN) is the first 6 digits of a credit or debit card, and it identifies the bank that issued it - and if you want to know if a number is a real credit card or just a bunch or random digits, it&#8217;s a huge help. While credit card numbers do use the <a href="http://en.wikipedia.org/wiki/Luhn_algorithm">Luhn algorithm</a> (mod 10 check) to see if the number is valid, it still produces a huge false-positive rate.</p>

<p>For an application like <a href="https://github.com/adamcaudill/ccsrch">ccsrch</a>, having this data available would be very handy to reduce false positives when scanning a large file system (scanning a large server produces a huge number of possible hits), but for what I would call fairly misguided reasons, the official registrar of these numbers (the <a href="http://www.aba.com/default.htm">ABA</a>) doesn&#8217;t make this data publicly available. As a result many people have pulled together what data they could find and made it freely available.</p>

<p>So I&#8217;ll add my name to that list.</p>

<p>I&#8217;ve pulled data from many public sources (sorry, I didn&#8217;t keep very good notes as to the sources) and cleaned it up to a reasonable point. All told, I&#8217;ve probably spent 40 hours or more cleaning this data up and getting it to a usable state. It contains over 60,000 entries, including major credit cards (Visa, MasterCard, Amex, Discover) as well as a few merchant entries.</p>

<p>Each record contains the following:</p>

<ul>
<li><p>IIN</p></li>
<li><p>Type (Mastercard, Visa, Visa Credit, etc.)</p></li>
<li><p>Name (Issuer name)</p></li>
<li><p>Length</p></li>
</ul>


<p><strong>Data Quality</strong></p>

<p>It&#8217;s not perfect. It&#8217;s from public sources so there may be errors, and there are some duplicates from cases where I wasn&#8217;t able to determine who the IIN actually belongs to. I&#8217;ve also updated for name changes and mergers where possible, but I&#8217;m sure I&#8217;ve missed a few and there are some where the assets where split, so I don&#8217;t know who the correct owner actually is (Washing Mutual being the leading example of this).</p>

<p>In general, I leaned to the side of caution - so if I didn&#8217;t know for sure, I left the duplicate in.</p>

<p>If you need absolutely correct data - contact the ABA, they are the only source that can give you the completely accurate listing. If you need to have a decent idea if a number is valid for most cases - I would say that this data is good enough.</p>

<p><strong>Warranty</strong></p>

<p>Just to make it really, really, really clear: There is no guarantee that this data is accurate, that it won&#8217;t cause to lose your job, cause your house to burn down, or cause Rebecca Black&#8217;s <a href="http://www.youtube.com/watch?v=kfVsfOSbJY0">Friday</a> to get stuck in your head (yup, you&#8217;re welcome ;)).</p>

<p><strong>Copyright</strong></p>

<p>Based on my understanding of US copyright law, it is my understanding that this data is not subject to copyright as it is a compilation of facts and doesn&#8217;t constitute an original expression. Thus, to the best of my knowledge, this data is in the public domain.</p>

<p><strong>Download</strong></p>

<p><a href="http://adamcaudill.com/files/2012/01/IIN.zip">Here</a> (zipped CSV)</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/01/23/poking-mykonos/">Poking Mykonos</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-23T22:28:56-05:00" pubdate data-updated="true">Jan 23<span>rd</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>While checking on the latest updates in the start-up world from TechCrunch, I came across <a href="http://techcrunch.com/2012/01/23/mykonos-helps-companies-battle-hackers-raises-4-million/">their article</a> on <a href="http://www.mykonossoftware.com/">Mykonos</a>; the important part of their article (at least for me), is this:</p>

<p><em>Mykonos’s Web Security product uses deception to “detect, confuse, slow down and prevent attackers” in real-time in order to help companies protect their websites and Web apps from malicious hacker and proactively prevent fraud and theft.</em></p>

<p>A couple of minutes of reading, and my interest was piqued - to say the least. The thing that most interested me was the claim of no false positives, while they do <a href="http://www.mykonossoftware.com/early-detection.php">talk about it</a> - I really wanted to see it for myself. Assuming they used their own product to protect their site, I took a few minutes to see what I could find - and find I did.</p>

<p>The first thing I did was a view-source to see what I could learn about their site - mainly to see if there were any obvious signs of using one CMS or another. The first thing that jumps out at me is this from the HTML:</p>

<pre><code>&lt;!-- InstanceBegin template="/Templates/mykonos.dwt.php"
     codeOutsideHTMLIsLocked="false" --&gt;
</code></pre>

<p>So, this tells us they are using Dreamweaver, and the name of the template. So, the next question is, does that <a href="http://www.mykonossoftware.com/Templates/"><code>/Templates/</code></a> directory exist on the server?</p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1930.png" alt="File Listing" /></p>

<p>Yup.</p>

<p>So, not only does it exist, they have directory listings turned on - which to me was a real shock. Unfortunately for us though, these files are named with the <code>.php</code> extension and not the <code>.dwt</code> I was hoping for, so we can&#8217;t get much useful from them.</p>

<p>So, from looking at the source of the home page, we can see that the css files are stored in a <a href="http://www.mykonossoftware.com/css/">/css/</a> directory - maybe that&#8217;ll be interesting.</p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1935.png" alt="File Listing" /></p>

<p>It&#8217;s there, and like last time, we can see all of the files. While CSS files are of no real interest, the <a href="http://www.mykonossoftware.com/css/_notes/">/_notes/</a> directory is, because it&#8217;ll contain a file called <code>dwsync.xml</code> - which can be quite interesting (since we knew they are using Dreamweaver, it&#8217;s not too surprising to see this). This file contains data about the last time the site was pushed from Dreamweaver, and will contain one entry per file, and looks like this:</p>

<pre><code>&lt;file name="style.css"
 server="ftp.belincreative.com/public_html/clients/mykonos/site/"
 local="129651858311162109"
 remote="129651936600000000"/&gt;
</code></pre>

<p>The most interesting thing there is the <code>server</code> entry, as it tells us a little about the file-system; which if we were really trying to attack the site, knowing that would be handy. The other thing of interest is that when you see one <code>/_notes/</code> directory, you&#8217;ll see lots more, as Dreamweaver likes to put them everywhere.</p>

<p>So, let&#8217;s see if there&#8217;s one in the root - that should be the most interesting one. Sure enough: <a href="http://www.mykonossoftware.com/_notes/">/_notes/</a></p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1949.png" alt="" /></p>

<p>This one has a few interesting entries, such as a <a href="http://www.mykonossoftware.com/TechSpecsWhatsNew.html">PHP file</a> that is named with an HTML extension - causing the code not to execute. Viewing the source of that file in the browser exposes the <a href="http://www.mykonossoftware.com/inc/">/inc/</a> directory; potentially interesting, but yields little information. The next file I tried (knowing it would be way too easy if it worked), was the <a href="http://www.mykonossoftware.com/.htaccess">.htaccess</a> file:</p>

<pre><code>&lt;files "webadmin.pl"&gt;
    AuthUserFile /usr/local/www/public_html/.htpasswd
    AuthType Basic
    AuthName "Server Administration"
    require valid-user
&lt;/files&gt;
</code></pre>

<p>Now, at first glance things look too good to be true - and that&#8217;s because they are. Look at the path in <code>AuthUserFile</code> and compare that to the entries from the <code>dwsync.xml</code> files. This <code>.htaccess</code> file is part of the trap, which is all but confirmed if you try to go to the <a href="http://www.mykonossoftware.com/.htpasswd">.htpasswd</a> file which shouldn&#8217;t work, since the path isn&#8217;t what we would expect.</p>

<p>Now, while mucking around looking at the aforementioned files, and others such as <a href="http://www.mykonossoftware.com/robots.txt">robots.txt</a>, I would periodically see this, which I would assume is part of that &#8220;no false positive&#8221; promise:</p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1716.png" alt="" /></p>

<p>I was hoping to run into the firewall (for lack of a better term) - looks like I got my wish; though since I wasn&#8217;t using anything automated and was just poking around by hand, it didn&#8217;t have any impact. Not terribly exciting, but it did provide some insight into what they are doing.</p>

<p>So far we&#8217;ve found a few interesting things, and bumped into their firewall, but that all pales in comparison to the last entry in the <code>dwsync.xml</code> file:</p>

<pre><code>&lt;file name="local-site.zip"
 server="ftp.belincreative.com/public_html/clients/mykonos/site/"
 local="129695851046591796"
 remote="129695888400000000"/&gt;
</code></pre>

<p>When I saw the file name I was shocked - could it really be? But I was right. It&#8217;s a 59MB file containing everything on the site - all the PHP and everything else. Out of curiosity, I compared the <code>.htaccess</code> to that in the zip file, as expected it&#8217;s quite different and more believable:</p>

<pre><code>Options +FollowSymlinks
RewriteEngine on
rewritecond %{http_host} ^mykonossoftware.com [nc]
rewriterule ^(.*)$ http://www.mykonossoftware.com/$1 [r=301,nc]
</code></pre>

<p>That confirms what I suspected, the file I saw earlier was just part of the trap.</p>

<p><strong>So what have we learned?</strong></p>

<p>1). Mykonos makes a really cool product, and had I not known what I was up against (and thus less skeptical about everything) it probably would have killed a lot of my time - just as intended.</p>

<p>2). No matter what you put in front or your site or application,<em> human mistakes are still your greatest risk</em>. A second set of eyes and a little paranoia go a long way in securing your systems, and stopping hackers.</p>

<p>3). Mykonos was either lucky or smart in that there was little on their site that shouldn&#8217;t be seen by the public. If they were using a CMS with a database back-end instead of simple (mostly-)static pages, this could have been worse. If they had source code or other valuable IP on the server, a mistake like this could be devastating.</p>

<p>4). Mykonos should take some of their new-found cash and hire somebody to finish the audit of their site that I started. ;)</p>

<p><em>Note:</em> I notified Mykonos about that zip file before posting this (through a couple of channels), and I&#8217;m intentionally not linking to it. While I didn&#8217;t see anything in there that would be an issue to be publicly disclosed, I&#8217;m sure they don&#8217;t want it getting out. Hopefully by the time anybody reads this, they will have taken care of that file.</p>

<p><em><strong>Update:</strong></em> As expect, they&#8217;ve cleaned up the files I mentioned - and a bit more. In a <a href="http://twitter.com/#!/dkoretz/status/162033710202486786">tweet</a> from the company&#8217;s CEO, <a href="http://www.davidkoretz.com/">David Koretz</a>, he mentioned that they had left a surprise for me. So I went to my starting point (the <code>/Templates/</code> directory), and was greeted with this:</p>

<p><img src="http://adamcaudill.com/files/2012-01-25_0005.png" alt="Welcome &amp; Thanks" /></p>

<p>Yeah, cool product and cool people. I&#8217;m impressed.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/01/15/google-chrome-leaking-credit-card-data/">Google Chrome Leaking Credit Card Data?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-15T11:04:04-05:00" pubdate data-updated="true">Jan 15<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>While testing <a href="https://github.com/adamcaudill/ccsrch">ccsrch</a> I noticed a number that looked familiar - my debit card number. Now, being just a little paranoid, I don&#8217;t leave such information on my system unencrypted - so seeing it was a real surprise. But, here&#8217;s the real kicker: it was on my work PC, where it never should have been. But there it was, plain as day, in clear text. I spent a couple of minutes staring at the log trying to figure out why it would be there.</p>

<p>Once I saw the file name, a sinking feeling set in and the answer became clear:</p>

<p><code>%LocalAppData%\Google\Chrome\User Data\Default\Sync Data\SyncData.sqlite3</code></p>

<p>So it turns out that it&#8217;s Chrome&#8217;s <a href="http://support.google.com/chrome/bin/answer.py?hl=en&amp;answer=165139">sync</a> feature that was saving my information, but why?</p>

<p>It turns out that auto-fill data is synced with your Google account (if you&#8217;re signed in and have the feature enable, of course), and all of the computers you&#8217;re signed into - and by default, without the benefit of encryption. This file may contain any number of things, from mine I was able to extract the following:</p>

<ul>
<li><p>Full name</p></li>
<li><p>Wife&#8217;s full name</p></li>
<li><p>Date of birth</p></li>
<li><p>Wife&#8217;s date of birth</p></li>
<li><p>Social Security Number</p></li>
<li><p>Multiple credit card numbers</p></li>
<li><p>Multiple <a href="http://en.wikipedia.org/wiki/Card_security_code">CVV</a>s</p></li>
<li><p>Bank account &amp; routing number</p></li>
</ul>


<p>Not to mention quite a few websites I&#8217;ve been to, various addresses, employer&#8217;s name and other various useful tidbits. All would be quite useful for identity theft or highly targeted <a href="http://www.fbi.gov/news/stories/2009/april/spearphishing_040109">spear phishing</a>.</p>

<p>Now am I saying that syncing auto-fill is bad? No, not at all. It&#8217;s a very useful time saver, but what takes it from a useful feature to security issue is the fact that by default, this <em>data isn&#8217;t encrypted</em>!</p>

<p><img src="http://adamcaudill.com/files/2012-01-15_0905.png" alt="Default Encryption Setting" /></p>

<p><strong>What are the risks?</strong></p>

<p>There are three significant risks I see here:</p>

<p>1). <em>Disclosure to less trusted systems</em>:</p>

<p>In my case, I trust my laptop to be secure; between full-disk encryption (via <a href="http://www.truecrypt.org/">TrueCrypt</a>) and other precautions, I know that I don&#8217;t have too much to worry about. On the other hard, my Work PC is on a corporate domain, and at least a couple dozen people have permissions sufficient to access my personal files - thus I don&#8217;t trust anything too valuable on it.</p>

<p>Now because of the fact that this feature is insecure by default, that data is exposed to a less trusted system.</p>

<p>It can also go the other way: a number of auto-fill entries on my personal laptop were from forms on internal-only applications that only my Work PC would be able to access. So this means that anything sensitive could be leaked to home networks which are typically less secure than corporate environments. If you routinely handle PCI, HIPAA, or other restricted information - this type of leak could be a major issue.</p>

<p>2). <em>Spear Phishing</em>:</p>

<p>Let&#8217;s imagine a scenario:</p>

<p>You work for a defense contractor and I work for a foreign intelligence agency. Through some targeted attacks I manage to penetrate your home network, but have been unable to make it into your corporate network. I grab the sync database file from your home PC and extract one of your credit card numbers. I look up the <a href="http://en.wikipedia.org/wiki/List_of_Issuer_Identification_Numbers">IIN</a> and find out what bank the card is from. Once I have this, I build a PDF with the latest 0day exploit, and send it with a convincing subject line:</p>

<p>&#8220;Important Information about your Bank of America credit card ending in 7850&#8221;</p>

<p>Normally you&#8217;d dismiss it as spam, but the last four digits are right - so you open it, just in case. The exploit kicks in. I&#8217;m in, you&#8217;re done.</p>

<p>This is just a simple and quite contrived example, but you get the idea.</p>

<p>3). <em>Google Data Mining</em>:</p>

<p>This is the most paranoid and least likely, but given Google&#8217;s issues in controlling their people - I&#8217;d say not impossible (see <a href="http://www.electronista.com/articles/10/05/14/google.admits.collecting.wi.fi.info.with.map.team/">here</a>, <a href="http://searchengineland.com/google-chrome-page-will-have-pagerank-reduced-due-to-sponsored-posts-106551">here</a>, and <a href="http://boingboing.net/2012/01/13/google-fraudulently-solicits-f.html">here</a>).</p>

<p>Just for a moment, think about the fact that Google has the following:</p>

<ul>
<li><p>Your account data (name, email, etc.)</p></li>
<li><p>Your auto-fill history (see the list of items I found above)</p></li>
<li><p>Tons of data from their other services</p></li>
<li><p>At least parts of your browsing history, if not much of it</p></li>
<li><p>Engineers that truly enjoy data mining</p></li>
</ul>


<p>Most other companies I wouldn&#8217;t worry about; but knowing the people that Google hires, and the skill they have in manipulating data - you know that some engineer is using his <a href="http://www.nytimes.com/2007/10/21/jobs/21pre.html">20% time</a> to do this (or at least is wishing he could).</p>

<p>If nothing else, I know if I worked at Google - playing with this data would be tons of fun. ;)</p>

<p><strong>Want to see your data?</strong></p>

<p>To see what Chrome has saved about you, download <a href="http://sqlitebrowser.sourceforge.net/">SQLite Browser</a>, and open the file I mentioned above. Go to the &#8220;Browse Data&#8221; tab, and select the &#8220;metas&#8221; table. What you&#8217;re looking for is in the &#8220;non_unique_name&#8221; column (among other places). You should see something like this:</p>

<p><img src="http://adamcaudill.com/files/2012-01-15_0942.png" alt="SQLite Browser" /></p>

<p>The entries starting with &#8220;autofill_entry&#8221; are the ones you are interested in, but you&#8217;ll likely find some of the other records interesting as well. If you see the word &#8220;encrypted&#8221; then your data is already encrypted, and you don&#8217;t have to worry about this.</p>

<p><strong>Is this a vulnerability in Chrome?</strong></p>

<p>No, not at all - though it was a mistake. They should encrypt everything by default, and not provide an option to do otherwise. There&#8217;s no reason to expose users to a potential security risk when there&#8217;s a simple fix. Security isn&#8217;t something users should have to opt-in to; and unless there&#8217;s a very good reason, they shouldn&#8217;t have a way to opt-out.</p>

<p>Google should understand security and the value of the data they hold; they should be more responsible for the data (and faith) people give them.</p>

<p><strong>How do I fix it?</strong></p>

<p>Simple, from the &#8220;wrench&#8221; menu, select Options -> Personal Stuff -> Sign In -> Advanced&#8230; and then under &#8220;Encrypted data types&#8221; select &#8220;Encrypt all synced data&#8221; - and that&#8217;s it. After a couple of minutes the entries that were visible before will now just display the word &#8220;encrypted.&#8221;</p>

<p><img src="http://adamcaudill.com/files/2012-01-15_0944.png" alt="Encrypt all data" /></p>

<p>You can also go a step further, and get rid of this data by disabling auto-fill to ensure that potentially sensitive information isn&#8217;t being persisted when it shouldn&#8217;t be.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/01/14/ccsrch-v1-0-5/">CCSRCH v1.0.5</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-14T08:08:39-05:00" pubdate data-updated="true">Jan 14<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>During my employers annual <a href="https://www.pcisecuritystandards.org/">PCI</a> audit, our auditor requested that we perform a search of all of our servers for credit card data. He recommended a tool called &#8220;ccsrch&#8221; - which like many open source projects had a couple of issues, and hadn&#8217;t been updated in years. So, I fixed it.</p>

<p>CCSRCH is a cross-platform, command-line application that reads every file from the starting point passed in, and scans them for what looks like credit card numbers (and using the <a href="http://en.wikipedia.org/wiki/Luhn_algorithm">Luhn algorithm</a> to check each possible result). It&#8217;s fairly brute-force, but it gets the scans required for PCI - though I would be careful about using it during production hours, it can have a pretty significant impact on a server&#8217;s I/O performance.</p>

<p>I&#8217;ve forked the application and setup a new <a href="https://github.com/adamcaudill/ccsrch">ccsrch</a> project over at github (the original is on <a href="http://sourceforge.net/projects/ccsrch/">SourceForge</a>), and made a few modifications to better suit my needs (from the <a href="https://github.com/adamcaudill/ccsrch#readme">change log</a>):</p>

<ul>
<li><p>Added option to output the file name, and how many hits were found to the console when using -o (see -c in usage).</p></li>
<li><p>Added option to limit the number of results from a single file before going on to the next file (see -l in usage).</p></li>
<li><p>Added option to exclude certain file types from the scan (see -n in usage).</p></li>
<li><p>Fix for ignoring NULL, CR &amp; LF.</p></li>
<li><p>Ignore dash when scanning.</p></li>
<li><p>Exclude results with the last 8 digits repeating (very unlikely to be a real PAN).</p></li>
</ul>


<p>I&#8217;ve <a href="https://github.com/adamcaudill/ccsrch/downloads">uploaded</a> a Windows build of the new 1.0.5 release to github, and for *nix systems, you can just download the latest <a href="https://github.com/adamcaudill/ccsrch/tags">tag</a>.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/page/14/">&larr; Older</a>
    
    <a href="/archives/">Blog Archives</a>
    
    <a class="next" href="/page/12/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p><img src="https://1.gravatar.com/avatar/49e14cf9f67c48aad082dec4f106f19a?size=250" class="aligncenter"></p>
  <p>I am an independant security researcher and software developer with more than 15 years of experience. I primarily focus on application security, secure communications, and cryptography, though often research new areas if I get too bored. I write about my research and security in general, development and software design, and whatever hobby has my attention at the moment.</p>
  <p>Email: <a href="mailto:adam@adamcaudill.com">adam@adamcaudill.com</a> (<a href="https://adamcaudill.com/pgp/">PGP</a>)</p>
</section>
<section>
  <h1>Links</h1>
	<ul>
		<li><a href="https://twitter.com/adamcaudill">Twitter</a></li>
		<li><a href="http://www.linkedin.com/in/adamcaudill">LinkedIn</a></li>
		<li><a href="https://github.com/adamcaudill">GitHub</a></li>
		<li><a href="http://www.flickr.com/people/adamcaudill/">Flickr</a></li>
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2015/05/18/making-bsides-knoxville/">Making BSides Knoxville</a>
      </li>
    
      <li class="post">
        <a href="/2015/04/13/crypto-front-door-everyone-welcome/">Crypto Front Door: Everyone Welcome!</a>
      </li>
    
      <li class="post">
        <a href="/2015/03/08/on-the-underhanded-crypto-contest/">On the Underhanded Crypto Contest</a>
      </li>
    
      <li class="post">
        <a href="/2015/02/17/the-evolution-of-paranoia/">The Evolution of Paranoia</a>
      </li>
    
      <li class="post">
        <a href="/2015/01/12/religion-free-speech-freedom-from-offense/">Religion, Free Speech & Freedom from Offense</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/adamcaudill">@adamcaudill</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'adamcaudill',
            count: 4,
            skip_forks: false,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Enjoy this site? Consider donating via Bitcoin to <strong>14jumFDmuVkLiAt4TgyKt17SWHtPRbkcLr</strong>.<br>
  Copyright &copy; 2015 - Adam Caudill -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
