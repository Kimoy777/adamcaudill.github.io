<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Adam Caudill]]></title>
  <link href="https://adamcaudill.com//atom.xml" rel="self"/>
  <link href="https://adamcaudill.com//"/>
  <updated>2015-03-06T21:29:30-05:00</updated>
  <id>https://adamcaudill.com//</id>
  <author>
    <name><![CDATA[Adam Caudill]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Evolution of Paranoia]]></title>
    <link href="https://adamcaudill.com//2015/02/17/the-evolution-of-paranoia/"/>
    <updated>2015-02-17T22:11:00-05:00</updated>
    <id>https://adamcaudill.com//2015/02/17/the-evolution-of-paranoia</id>
    <content type="html"><![CDATA[<p>That researchers from Kaspersky Lab uncovered malware that uses <a href="https://blog.kaspersky.com/equation-hdd-malware/">hard-drive firmware</a> has now been throughly discussed — perhaps too much for some people. It’s not exactly Earth-shattering news either, the idea has been discussed for years, and has been <a href="http://spritesmods.com/?art=hddhack">publicly demonstrated</a>. <a href="http://brandonw.net/">Brandon Wilson</a> and I were even working proof of concept for SSD controllers to demonstrate this based on our <a href="http://adamcaudill.com/2014/10/02/making-badusb-work-for-you-derbycon/">BadUSB</a> work.</p>

<p>This isn’t about that story, exactly. This is about paranoia, and how it has changed over the last few years — and even the last few months.</p>

<p>I was talking to Brandon Wilson about the implications of Kaspersky’s discovery, and how, or even if, you could ever trust your platform. When you could have malicious firmware in key system components — hard drive, USB devices (keyboard, mouse, etc.), USB hub — and possibly others, how about the GPU or the webcam that’s in virtually all laptops, how could you ever feel secure? How would you ever even know about it? Every device that has updatable firmware is a possible target, and far too few of them use any form of effective security to prevent malicious changes.</p>

<p>I pointed out that I buy all of my computers and key hardware from stores, I don’t have any of it delivered. Why? <a href="http://www.forbes.com/sites/erikkain/2013/12/29/report-nsa-intercepting-laptops-ordered-online-installing-spyware/">Interdiction</a>.</p>

<p>If it has my name associated with it prior to being in my hands, how do I know that it’s not been tampered with? Prior to Edward Snowden, I would have said that it was paranoid, that taking such precautions was at best a waste of time and at worst a sign of delusion. Today? If you are working in a field where you could have useful information, it seems quite reasonable. Paranoia has evolved, it has changed, what was once unreasonable is now prudent.</p>

<p>It was of course known that such things were possible before Snowden, but the scale was unknown — and of course NSA and the FBI aren’t the only threats, if they are doing something, you can bet they are far from alone. When that Lenovo laptop was shipped from China, do you really think that the Chinese Government wouldn’t take that chance to step in to gather some extra information? Launch-day iPhones have been shipped directly from China, and so many other examples. If NSA can tamper with a shipment, so can any country that has even temporary access to a package; if it’s on their land, they can attack it.</p>

<p>The focus has been on what NSA does, but the information should be used not as a way to attack NSA, but to get an insight to the  global threats that everybody that could be of interest faces. It’s important to remember that they don’t just <a href="http://www.theregister.co.uk/2014/02/03/nsa_gchq_accused_of_hacking_belgian_smartcard_crypto_guru/">target</a> <a href="http://arstechnica.com/tech-policy/2013/11/uk-spies-continue-quantum-insert-attack-via-linkedin-slashdot-pages/">terrorists</a>.</p>

<p>I recently had a person contact me, concerned that a device she had was compromised — while I could tell her that unless she was attracting attention from a major player she was likely safe, I couldn’t tell her that she actually was safe, or anything she could do to ensure that nothing was infected. As these techniques spread to more common attackers, the risks that average people will be targeted grows dramatically. Attacks not only get better over time, they become more widespread. From repressive regimes that outsource their attacks, to poorly supervised local law enforcement, to common malware — it’s only a matter of time.</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p>Today&#39;s NSA malware is tomorrow&#39;s everywhere malware. Defenders are so screwed.</p>&mdash; Matthew Green (@matthew_d_green) <a href="https://twitter.com/matthew_d_green/status/567869974246596609">February 18, 2015</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>Defending against these attacks, without major changes from device manufacturers, is at best a nightmare; at worst, impossible. I have repeatedly called out USB controller manufacturers to secure their devices, as that’s the only way that BadUSB can be truly fixed. The same needs to be said for so many other device types — it’s up to device manufacturers to secure their products.</p>

<h2>The Chain of Trust</h2>

<p>For any system to be secure, there must be trust at some point, which can then ensure that later layers are correct and untampered. By attacking firmware, the chain is defeated at its first link — attack the hardware at the lowest level, and nothing that comes later, including the operating system, can truly be trusted.</p>

<p>The more important impact though is not technical, but psychological. If a person doesn’t know what they can or can’t trust, they start to fear everything. For NSA, GCHQ, and countless other agencies in the same business, this is good news — if people can’t trust their computers or their phones, they will turn to less secure means of communication. This is also extremely bad for consumers, business, and investors — as these tools can be used not just to go after government selected targets (legitimate or otherwise), but for profit, for blackmail, for revenge, or just for a thrill.</p>

<h2>Targets</h2>

<p>While the public focus of NSA is to combat terrorists, it’s been well documented that their targets go far beyond that — researchers, IT staff, business executives, you name it. Yet, I’m a citizen of the United States, and as such, I <em>shouldn’t</em> be a potential target for them (give or take being caught up because of people I know in other countries). Is that the end of the risk for me? No, not by a long shot.</p>

<p>While the <a href="https://en.wikipedia.org/wiki/Five_Eyes">Five Eyes</a> countries share intelligence, they don’t share restrictions on who they can spy on. For GCHQ, whether I’m a citizen of the United States or of Afghanistan makes no difference, I’m a valid target under their laws. Canada, Germany, Russia, China, Taiwan — I’m not protected under their laws, if they think I could have interesting information, or access to interesting information, on any topic, I could be a target. So could you. What information do you have access to, who do you know, and what information could they have access to?</p>

<p>If you work in security, development, IT, telecom — that could mean that you have access to some information that some country would like to have. Is that paranoia? A few years ago, some would say yes — now that we have a better insight into the scope and scale of intelligence activities, we know it’s simply reality.</p>

<h2>Personal Threat Models</h2>

<p>I have long encouraged people to have a personal threat model — what are your realistic threats? When talking to others, keep in mind that their threat model may be different than yours, and things you see as being paranoid could be quite prudent for them, due to the different risks they face.</p>

<p>For me, to be honest, I’m not that interesting to a foreign power — if anything, trading emails with Glenn Greenwald and trading tweets with people like <a href="https://twitter.com/thegrugq">the grugq</a> has done more to make me a target than any professional activity. The information I can access because of my job is somewhat interesting, and is certainly of value — but more to the Russian Mob than to a foreign government. I pay attention to who I talk to, to what I make public, to what my accounts have access to, so I know what my risks are.</p>

<p>If you work for a more interesting company, or are engaged in research that could be useful, or even just know people that could be more interesting than you, your threats could be completely different. Of course, also have to factor in locations — if you are outside of the US and work for a company that could have interesting information, then your threats may be far more complex.</p>

<p>Defining the line between reasonable and paranoid is harder than ever, and may vary from person to person.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Religion, Free Speech & Freedom from Offense]]></title>
    <link href="https://adamcaudill.com//2015/01/12/religion-free-speech-freedom-from-offense/"/>
    <updated>2015-01-12T01:51:00-05:00</updated>
    <id>https://adamcaudill.com//2015/01/12/religion-free-speech-freedom-from-offense</id>
    <content type="html"><![CDATA[<p><a href="http://zombietime.com/mohammed_image_archive/islamic_mo_full/"><img class="center" src="https://adamcaudill.com//files/muhammad.jpg"></a></p>

<p>When I was a teenager I worked as a photojournalist and through that experience I learned just how important it is that the public, and the press in particular be able to speak openly, freely, and without restriction.</p>

<p>I also learned how important discretion is — I routinely worked events where people died, those people had families and they would see the photographs that documented the end of a life. Photos chosen for publishing had to be carefully picked, making the wrong choice could offend some, and truly hurt others. I saw people break down and cry when seeing photos I took — I saw the results of brash carelessness on families that were already hurting, already devastated.</p>

<p>I once was tasked with documenting a hate crime — a black effigy hung from a tree, followed shortly thereafter by a body found in a river — hands bound, and clearly related. People were scared, the mock hanging was a warning, and the body found proved that the threat was real. What gets shown and what doesn’t in cases like this is a very difficult choice. On one hand you risk offended and inciting fear — maybe even panic, on the other, you withhold useful information, stifle discussion, and risk leaving the truth sitting in a box, hidden from the world.</p>

<p>For all of the bad, there was also good — lives changed, hard questions asked, reforms enacted, true change made. This wasn’t done without stepping on toes though, hard decisions had to be made to find the right balance.</p>

<p>Making people comfortable is easy — give them what they want and no more. To make people think though, requires making them uncomfortable, requires pushing them outside of their comfort zone — and occasionally, offending them.</p>

<h2>The attack on Charlie Hebdo</h2>

<p>I firmly believe that journalism, legitimate journalism, is among the most critical tasks in a free society. Shining a light on the good and the bad — the eyes and ears of the people, too often the last chance for justice. When questions can’t be asked, when public figures are put beyond satire and debate, when some topics are unquestionably untouchable, then freedom dies. Slowly at first, then the line inches ever forward until the press is nothing but a mouthpiece for their puppet masters and feeding the public little more than entertainment - no challenges, no discomfort, no thought required entertainment.</p>

<p>Charlie Hebdo made a habit of making people uncomfortable — they attacked everyone and everything in power, they left nothing untouched. In doing so they offended almost everyone — some got mad and stomped away; others took it as a chance to reflect, not  only on the statement, but their own reactions, feelings, and beliefs; a few though decided that they needed to die for it.</p>

<p>Those at Charlie Hebdo worked despite threats and attacks, they continued in the face of danger. Every issue published was an act of bravery — sometimes tasteless, sometimes wantonly offensive, but still an act of bravery.</p>

<p>In a effort to silence the criticism of their preferred historical figure, a small group following an extreme and radical interpretation of a religion, took it upon themselves to silence journalists and artists by force. The goal though, went far beyond Charlie Hebdo — the attack was meant to send a wave of fear and terror throughout the world and leave journalists too afraid to say anything or risk a similar fate.</p>

<p>In the hours after the attack, there were clear indications that the extremists that sought to censor the world, may have actually <a href="http://www.huffingtonpost.com/2015/01/07/charlie-hebdo-censorship-cartoons_n_6431854.html">achieved that goal</a>. Publications around the world censored the cartoons of Charlie Hebdo, an act I consider to be cowardice, and willing, knowing capitulation. In the face of danger, some will choose to be brave and stand for what they believe — others will abandon what they believe readily when faced with the threat, or even the idea of danger.</p>

<p>Nothing is beyond ridicule, no person above satire — not political leaders, not Muhammad, not Jesus, not Zoroaster, not Zeus, not Ra, not Utu.</p>

<h2>#JeSuisCharlie</h2>

<p><a href="http://blog.erratasec.com/">Robert Graham</a> posted an <a href="https://twitter.com/ErrataRob/status/552862494684094464">image on Twitter</a> that immediately gave me mixed feelings; I agreed and disagreed all at the same time. On one hand, the image is the very definition of satire — it’s a strong point on the perception that these religious extremists are leaving many with. On the other hand, it could further inflame the situation,  insulting some and adding more energy to those that have shown they will not be subject to rational thought. It was also an act of defiance, a statement that he would not be censored, and a recommendation that others should follow his example and show that the world will not allow a group of extremists to define what’s acceptable.</p>

<p><img class="center" src="https://adamcaudill.com//files/jesuischarlie.png" width="299" height="338"></p>

<p>For those that are offended by this image, I’m sorry that you feel as you do — though I will offer no apology for posting it. Offending for the sake of offense should be avoided — and is an act I disagree with, offending for the sake of making a point though, is sometimes necessary.</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p>I rarely agree with H. Nasrallah but yes: &quot;Islamic extremists who slaughter people have done more harm to Islam than anyone else in history&quot;</p>&mdash; Karin Kosina (@kyrah) <a href="https://twitter.com/kyrah/status/553991337750827008">January 10, 2015</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>The point here is clear — irrational extremists are acting in unimaginable violence against those that they disagree with, and in doing so, branding the religion as one of violence and hate. This is a fact that everyone needs to understand.</p>

<h2>Religious Violence</h2>

<p>Violence and religion have went hand in hand throughout recorded history. Christianity has <em>mostly</em> moved away from violence and many of its ancient prejudices (though certainly not all) — something Islam is still struggling with, based on the extreme views and actions of not only terrorist organizations, but governments.</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p>Crowd shouted “Allahu akhbar” as Raif Badawi received 50 lashes for the crime of writing words. 950 more to come&#10;<a href="http://t.co/RRh97uaucT">http://t.co/RRh97uaucT</a></p>&mdash; Richard Dawkins (@RichardDawkins) <a href="https://twitter.com/RichardDawkins/status/553816128758501376">January 10, 2015</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>While extremists have done much to harm Islam, there seems to be a pervasive penchant for violence among the more ‘conservative’ Islamic countries — this acceptance of violence and frequent <a href="http://www.nytimes.com/2007/11/16/world/middleeast/16saudi.html?_r=0">perversions of justice</a> have also done much to make the world question the Islamic commitment to peace.</p>

<p>For me, as an atheist, knowing that there are thirteen Islamic countries where I could be <a href="http://www.reuters.com/article/2013/12/10/us-religion-atheists-idUSBRE9B900G20131210">put to death</a> for my lack of faith certainly makes me question just how much peace factors into Islamic views.</p>

<p>While most Muslims are peaceful, the large numbers that espouse peace through forced conformity and violence taint the view of the entire religion.</p>

<h2>Freedom from Offense</h2>

<p>One of the most bizarre and damaging perversions on the innate right to free speech, is that there is an implied inverse right to <em>not</em> be exposed to anything offensive. Yet this fictitious right to not be offended is antithetical to freedom of speech - you can have only one of the two.</p>

<p>A right to not be offended is a personal right that would trump the rights of all others — freedom of speech does not imply that anyone must listen, only that you have the right to speak. A right to not be offended would require others to not speak if you didn’t like what they had to say. Such a right is a logical impossibility — if we accept that there is truly an innate right to free speech, then there is no overriding inverse.</p>

<p>So the reality is simple — there are times to preserve the critical and innate right to free speech, that some will be offended.</p>

<p>One challenge for a journalist is to effectivly get a message across that challenges without offending more than absolutely necessary. I can’t say if Charlie Hebdo crossed that line, but even if they did, they were within their rights.</p>

<h2>All Speech Has Value</h2>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p>All speech, even the extremely stupid stuff, is valuable. I probably wouldn&#39;t understand evolution were it not for the insane creationists.</p>&mdash; Taylor Hornby (@DefuseSec) <a href="https://twitter.com/DefuseSec/status/554541092264108034">January 12, 2015</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>One final note, inspired by a friend, is that all speech — from the inane and ignorant to true hate speech can have some value. It provides insight, understanding, and perspective that would be missed otherwise.</p>

<p>For those that don’t share perspective with the speaker, such speech that many consider worthless can be a learning experience. You may never agree with them, but at least you can better understand them, and that may lead to clarity.</p>

<p>Embrace the speech that you disagree with and better understand the people behind a perspective that is new to you — it’s a chance to expand you mind, and maybe even bridge a gap and create new understanding.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Utopia Found; Utopia Lost]]></title>
    <link href="https://adamcaudill.com//2015/01/03/utopia-found-utopia-lost/"/>
    <updated>2015-01-03T19:14:00-05:00</updated>
    <id>https://adamcaudill.com//2015/01/03/utopia-found-utopia-lost</id>
    <content type="html"><![CDATA[<p>Sometime in the 1990’s I used a 2400-baud modem and connected to the internet for the first time; I found a new world, a better world. A world where ideas and intellect set people apart, not skin color, or political affiliation, of even the pseudo-scandal of the day (which is probably just a disguise for ignorance and intolerance).</p>

<p>It was a time of invention, in a world where everything was new and the potential was unlimited. It was magic - not the fake Hollywood magic, but real, life changing, nothing can hold you back magic. The only real restriction was your own mind (and maybe your long-distance bill).</p>

<p>Before too long I ran across a short essay that reinforced my view of the internet, and my philosophy towards people in general - <a href="http://phrack.org/issues/7/3.html">The Conscience of a Hacker</a>. While it resonated with me at the time, as it reflected my life so well, it was one small passage that really mattered to me:</p>

<blockquote><p>We exist without skin color, without nationality, without religious bias&#8230; and you call us criminals.</p><footer><strong>Loyd Blankenship</strong> <cite>The Conscience of a Hacker</cite></footer></blockquote>


<p>One simple line, yet such a profound statement. The internet I grew to love was a different world — national borders meant nothing, the freedom to speak your mind was simply assumed for all without question. Governments didn’t understand it well enough to care, and so it was ignored. A different kind of society was allowed to evolve — a society that valued people and intelligence greater than political or religious affiliation. A society where anyone, even a poor kid from the middle of nowhere could have a real impact on the world.</p>

<p>There was of course conflict, and egos, and the ever increasing encroachment of money that would change everything; but in general, it was good — better than any nation I was aware of.</p>

<h2>Utopia Lost</h2>

<p>Today, Solar Designer was commenting on Intel <a href="https://twitter.com/solardiz/status/551496338995937280">shutting down</a> certain Russian-language content due to a rather <a href="http://www.washingtonpost.com/world/russian-blogger-law-puts-new-restrictions-on-internet-freedoms/2014/07/31/42a05924-a931-459f-acd2-6d08598c375b_story.html">horrible Russian law</a>:</p>

<blockquote><p>Most people and most countries are their own worst enemies…</p><footer><strong>Solar Designer</strong> <cite><a href='https://twitter.com/solardiz/status/551498166366142465'>twitter.com/solardiz/status/&hellip;</a></cite></footer></blockquote>


<p>From the early, government ignored days of the internet, certain rights were assumed for all users — it was never written, but at the time it seemed that the internet was beyond any one government. It belonged to humanity, it was for the people. Of course, looking at the history of the internet, this is somewhat amusing, but it’s the way many felt, and it seems many still do.</p>

<p>Freedom of speech, freedom to speak anonymously, and so many others were granted by the internet to people that in the past had never had them. This great invention, this great network of people, had become the greatest tool of equality ever. Such things seem doomed.</p>

<p>As Solar pointed out - countries are their own worst enemies - in this case a horrible law is not only impacting the freedom of speech, but also to avoid the complications it introduces (and other similar laws recently enacted), companies are <a href="http://www.businessinsider.com/google-pulls-out-of-russia-2014-12">pulling out of Russia</a> or disabling functionality for Russian users. So the Russian people lose, the economy is impacted, everybody loses something when such mistakes are made.</p>

<p>Of course, this is far from a unique case — the old internet, the free, open, good for humanity internet is all but dead. It’s been a long time since governments discovered what they had ignored for so long, and that an international bastion of freedom had formed under their noses.</p>

<p>Censorship becomes more pervasive every day, the monitoring by the FIVE EYES countries - and who knows who else - is so pervasive that one has to now assume that anything not (securely) encrypted is being seen and analyzed by many. Malware vendors grow rich, by leveraging the greatest invention in human history as a tool for repression and even death. In Russia, exercising an innate human right can <a href="http://www.bbc.com/news/world-europe-16057045">send you to prison</a>, in Syria, <a href="http://thelede.blogs.nytimes.com/2012/02/21/syrian-video-blogger-reportedly-killed-in-homs-as-shelling-continues/?_r=0">it can get you killed</a>.</p>

<p>Complacency, subterfuge, infighting, and carelessness have allowed those with power and money to take more more control than they ever should have. Groups like the MPAA are still busy pushing bad laws, trade treaty negotiations continue to risk further censorship, and anti-terror laws are increasingly being aimed at online speech instead of legitimate threats.</p>

<p>The internet I fell in love with was a bastion of freedom. May it long be defended, even if all that’s left is the memory, and the idea of what it could again become.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014: Year In Review]]></title>
    <link href="https://adamcaudill.com//2015/01/01/2014-a-year-in-review/"/>
    <updated>2015-01-01T23:44:00-05:00</updated>
    <id>https://adamcaudill.com//2015/01/01/2014-a-year-in-review</id>
    <content type="html"><![CDATA[<p>Inspired by a post from <a href="https://scott.arciszewski.me/blog/2014/12/year-2014-reflection">Scott Arciszewski</a>, I&#8217;ve decided to go ahead and publish a year in review post. This is something that I&#8217;ve generally avoided in the past, as the tone of these posts is more often than not, just cynicism and negativity. After seeing Scott’s post, it made me think about how such a review can be used to send a positive message — something desperately needed.</p>

<p>Year after year, we see predictions, projections, and sales pitches — and the cynical responses that they always generate. It&#8217;s so easy to spend time rolling our eyes at vendors and media, instead of looking forward to ways to improve the situation and make the world a better place — even if only in a tiny way. We may not be able to fix the stupid, but we can at least reduce the damage that it does.</p>

<h2>2014 In Review</h2>

<p>So, without further ado, a personal look back at 2014.</p>

<h3>Security Research &amp; Related</h3>

<p>Overall this has been a very busy year, and I’ve not been able to publish as much as I’d like. In total, I requested only a single CVE for the entire year - <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-2890">CVE-2014-2890</a> (I don’t keep a count of how many security related tickets I open, so no idea how many issues I actually reported).</p>

<p>Most of my time was instead spent on a couple projects - <a href="https://github.com/smimp/smimp_spec">SMIMP</a> and <a href="https://github.com/adamcaudill/Psychson">Psychson</a> (BadUSB firmware). I’ll talk more about these later.</p>

<p>I wasn’t able to spend as much time on public application security work as I had intended, but I did get some reports in, some advice given, some progress made.</p>

<h3>Speaking</h3>

<p>In 2014 I was fortunate to be asked to speak on a few occasions. When preparing for a talk, I always have mixed emotions — on one hand, it&#8217;s always been a great experience, a chance to meet new people, share knowledge, and hopefully contribute to the community. On the other hand, it&#8217;s a significant amount of time that is lost — and time is without a doubt my most limited resource.</p>

<p>Whether it makes sense or not, I generally don&#8217;t give he same talk twice — especially if the event is recorded. So for each talk, it&#8217;s a real time &amp; energy commitment. I very much hope that those that have seen my talks appreciated them, and got something out of them.</p>

<p>Here is some information from selected talks:</p>

<ul>
<li><a href="https://adamcaudill.com/2014/08/16/smimp-at-the-defcon-cryptovillage/">SMIMP at the DEFCON Crypto Village</a></li>
<li><a href="https://adamcaudill.com/2014/10/02/making-badusb-work-for-you-derbycon/">Making BadUSB Work For You - DerbyCon</a> (YouTube video now over 100,000 views!)</li>
<li><a href="https://adamcaudill.com/2014/11/23/speaking-at-sc-magazine-congress/">Speaking at SC Magazine Congress</a></li>
</ul>


<h3>Personal</h3>

<p>Personally, this has been a particularly trying year for me, for various reasons. I have, as I always do, made a real effort to not show what&#8217;s going on when things go wrong. So, for all my friends, and everyone else for that matter — if there were times I was distant or difficult, or evasive — I am truly sorry.</p>

<p>With that said, the year could have been far worse, and I&#8217;m incredibly grateful for all the friends I have — old and new. It was a busy year, with much going on and never enough time to make everything that needed to happen, actually happen.</p>

<h3>Projects</h3>

<p>During the year, much of my time was taken up by a couple projects — here is where they stand today:</p>

<p><strong><a href="https://github.com/smimp/smimp_spec">SMIMP</a></strong> - Without a doubt the most ambitious project I&#8217;ve worked on, with a goal no less than replacing email itself. The first public draft was released in late July — and unfortunately remains basically untouched since then.</p>

<p>Shortly before I released the first public draft, a start-up tried to acquire the rights, so they could develop it, and build there own applications around it. By the time that I told them that I was more interested in making the specification public, they had offered me a position as co-founder in exchange for it.</p>

<p>This project took a substantial amount of time to get to a first draft — and really, it isn&#8217;t complete yet. Given the original goal of the project, leaving it with open issues really doesn’t bother me — that many more points to talk about.</p>

<p>The original plan for the effort was to spur discussion, to get people talking about how email could be replaced. To be secure, a system must be designed with certain goals and threats in mind - something that didn&#8217;t happen with email as we know it today. So to fix email, we need to replace it. SMIMP may not be the answer, but we need to do something.</p>

<p>Overall, though there was some positive feedback, I consider the project to be a failure. I&#8217;m proud of the work I did on it, but it didn&#8217;t have the desired effect.</p>

<p><strong><a href="https://github.com/adamcaudill/Psychson">Psychson (BadUSB Firmware)</a></strong> - Without a doubt the work that had the most people talking. It was a fun project, we managed to get some code in the hands of those that wanted to extend it.</p>

<p>It’s over, and I’m glad it’s over.</p>

<p><strong>Blog</strong> - This blog has also been a bit less active than I hoped — 16 posts with a total of 18,040 words. I’m pretty sure last year I said I’d blog more. Oops.</p>

<p><strong>My First Novel</strong> - A couple years ago I started occasionally working on an idea for a novel, this year, I set aside what I had been doing, and started fresh (but still based on the same material). My goal was to finish it this year, by there simply wasn&#8217;t enough time.</p>

<p>Writing is something that I have yet to determine if I&#8217;m actually good at - or if I just limp along enough for others to tolerate. While I could write a technical book with confidence, writing fiction is something that, quite intentionally, pushes what I&#8217;m comfortable with.</p>

<p>Making the time and finding the focus for something like this is certainly more difficult than I had imagined. I&#8217;ve come to understand why so many writers drink.</p>

<h3>Overall</h3>

<p>I have to say, I love the communities that I work with. I love that I get to deal with challenging problems. I love that I get to find solutions and make them work. But most of all, I’m thankfully for so many friends and great people that make this work truly enjoyable.</p>

<h2>Looking forward to 2015</h2>

<p>I have a number of goals for 2015, a number of projects that need my attention, and ideas to make the world just a little bit better.</p>

<ul>
<li>SMIMP - While I feel that the project generally failed, there doesn’t seem to be much movement in the let’s-kill-email space, so I don’t think it’s dead quite yet. There just might be another chance to get people talking about a real solution.</li>
<li><a href="https://github.com/adamcaudill/CurveLock">CurveLock</a> - An open source, secure, modern encryption application. This is mainly an experiment - but the goal is to provide high security, in a simple, easy to use application. Hopefully will get a beta out before too long.</li>
<li><a href="https://github.com/EncryptingCamera/encryptingcamera-spec">EncryptingCamera</a> - Prompted by a conversation on Twitter, a few people got together to make a new application that will hopefully protect a few reporters — and others that need to take photos, and secure them from inspection.</li>
<li>Blog - Last time that I promised to blog more often, I didn’t post again for months, so I’m hoping that I don’t repeat that this time. But I promise to write more, and do my best to keep the content interesting.</li>
<li>Personal Transparency - I’ve always been very concerned with my professional image, and as such tend to keep many details of my life to myself. One personal goal for this year is to be <em>just a bit</em> more open and transparent.</li>
<li>Novel - I intend to have either a deal signed with a publisher, or to publish as an ebook on Amazon before the end of 2015. One way or the other, I’ll be done with it by the end of the year.</li>
<li>Research - I plan on spending more time evaluation open source applications for security issues. In just a few hours a week, can have a real impact on making applications and users more secure.</li>
<li>Open Source Security Tools - I hope to dedicate a reasonable amount of time on new and existing tools to make users more secure, especially when it comes to secure communication. PGP/GPG hasn’t aged well - tools like <a href="https://github.com/tedu/reop">reop</a> have a lot of technical potential, but usability still needs to be improved.</li>
<li>More time outside of the echo chamber - It’s easy to stay inside of the echo chamber, agreeing with ourselves (or disagreeing), but what good does it really do? To have a real impact, we need to spend more time influencing the people that need our help the most.</li>
<li>Consume less, create more - In general, consume less and create more — time is a precious and limited resource, should be used to do as much good as possible.</li>
</ul>


<p>Oh, and one final note for next year - my wife and I are expecting again. Should be an exciting year.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Irrational Attribution: APT3.14159]]></title>
    <link href="https://adamcaudill.com//2014/12/20/irrational-attribution-apt3-dot-14159/"/>
    <updated>2014-12-20T23:01:00-05:00</updated>
    <id>https://adamcaudill.com//2014/12/20/irrational-attribution-apt3-dot-14159</id>
    <content type="html"><![CDATA[<p><em>[Note: This is satire / fiction; well, more or less - probably more more than less. Any resemblance to real companies, living or dead, is purely coincidental.]</em></p>

<p>WASHINGTON, D.C — Unnamed White House officials that spoke on the condition of anonymity, have stated that a major American company has been hacked, and the attackers are threatening to release terabytes of proprietary information. The name of the company has not been released at this time.</p>

<p>The officials say that the attack came from a state-sponsored attacker — the speed at which the attackers gained control of the company’s network, the focus on administrative credentials, and the sophistication of the previously unseen malware used in the attack. Based on IP addresses used, the attack has been tied to Belize.</p>

<p>Security researchers from Mendyant Security are working a new report, to be released next week. They have dubbed this new group APT3.14159 - and have identified prior attacks that share similarities with the new attack revealed today. They have identified the attackers as Unit 26478 of the Belize Defense Force.</p>

<p>Officials from the Belize Defense Force refused to comment on this story.</p>

<hr />

<p>“I just talked to the CEO, he wants hourly updates on our findings. Now that the FBI, and Mendyant Security is involved, he wants to know, real time, what’s going on and what we’ve found” said Bob, the middle-age middle-manager that had no experience with security, but accepted the position because it paid more.</p>

<p>“Bob, there are three of us, you have three analysts on the team - we are the entire security team, and we’ve been working for two days straight so far. We’ve had to shut down the entire network - even the core switches are down. We can’t access anything, the US data center is in New York, and the secondary in in Japan. We’ve spent the last two days just collecting notes and making sure that everything was shut down. Here’s your update: we know nothing besides that we were hacked.”</p>

<p>Jerry, a tall, slender, over-worked security analyst had spent the last two days trying to contain a massive hack that liked impacted everything inside the company. Having only three analysts that could do anything useful - and multiple managers that wanted constant updates so they would appear useful - the team was exhausted, confused, and unable to do anything at this point.</p>

<p>The attackers had sent company executives screenshots and file listings from the data they had collected, and demanded a ransom or they would release the data and destroy their systems - the executives couldn’t make anything of it, so assumed it wasn’t important. The security team wasn’t made aware of the emails until workstations started dying.</p>

<p>Two hours after the deadline passed, workstations throughout the multinational company started to fail. At first, the local technicians assumed it was just an unusual rash of hardware failures. By 9AM Eastern the next day, over 3,000 machines had been reported offline, with the number impacted climbing rapidly.</p>

<p>Then, finally, someone called the Director of Information Security - but by unfortunate coincidence he was in a meeting until 10AM. When he finally talked to the technicians, the number reported had grown to 5,500 - he immediately called the Senior Manager of Security Assurance. Unfortunately though, she worked in the west coast, and didn’t start her day until noon eastern time. She immediately realized that something very bad was going on, and asked the Manager of Systems Security (Bob), to have his team of analysts look into it. Bob though, though it was an Information Services issue, and directed the issue to the Senior Manager for Systems &amp; Infrastructure. Two hours later, after traversing his chain of command, he determined it was a security issue, and sent it back to the Senior Manager of Security Assurance. By the time it landed back on her desk, at 2PM Eastern, the number on downed workstations was now over 10,000 and 500 servers. She again passed the issue to Bob, and at 3PM the analysts were finally aware that something had happened.</p>

<p>Once the small team of security analysts were finally made aware, they quickly started to do damage control - disabling all connections to the internet, disconnecting the separate physical sites, anything they could think of to limit the spread of whatever this malware is.</p>

<p>One of the analysts quickly pulled an image of one of the local manager’s laptop, and began to analyze it on her personal machine - all the security analysts assumed that their machines would be wiped too, so any serious work was done on their personal laptops. Within an hour she identified an unusual file, that was named similar to a critical Windows file, but wasn’t signed by Microsoft. She uploaded the file to VirusTotal - none of the engines detected it as malicious, nor did their antivirus software of choice. She noticed that it referenced a well known driver used in commercial software to wipe drives before disposing of them - this looked like the smoking gun.</p>

<p>Thanks to her quick work, they were able to get technicians at local sites to begin cleaning up - by then end of the day, only half of their machines had been wiped. Had it not been for her identifying it, all of their Windows workstations and servers would have been wiped.</p>

<p>“Well, what do I tell the CEO Jerry?”</p>

<p>“Tell him there’s nothing more we can do, so we went to bed. We’ll be back tomorrow-ish” - and with that, the entire team (all three of them) walked out the door.</p>

<hr />

<p>Inside a five story brick office building, on the outskirts of San Francisco a team of analysts for Mendyant Security study the limited logs available and the sample of the malware the Sone Corp analyst found.</p>

<p>From looking at the debug information and embedded strings, there were clear signs of Spanish and Kriol - a dialect of Creole that is common in Belize. The mix of languages in the strings and in the file paths led the analysts to conclude that it wasn’t the work of a single person, but a multilingual team.</p>

<p>The logs indicated that the malware was connecting to China, India, Spain, and Russia. After some initial analysis, all of the Command &amp; Control servers used a particularly old version of a content management system, and were easily hacked. The analysts decided that seeing as these servers were likely hacked, and that the easiest way to gather information from them was to go ahead and hack them and collect whatever information they could.</p>

<p>Within a couple hours, they were downloading full copies of all the data on each of the servers. Once downloaded, they would study the C&amp;C software to see if anything interesting is going on.</p>

<p>The C&amp;C software was written in PHP, and did fairly little on its own - most of the commands were relayed back to a hard-coded  IP on port 31337. The server at that IP was no longer online, so  one of the analysts contacted a security researcher that had been performing internet wide scans, asking if he had any information for that IP. They were lucky, his logs showed that an HTTP server came online on that server a little over six months ago, and disappeared on his last scan, just two days ago.</p>

<p>Looking up the owner of the IP, it was register to the Belize Defense Force. APT3.14159 was born.</p>

<p>The story is clear, hackers for the BDF hacked the C&amp;C servers, having them relay to their own server; once detected, the main server was taken off line.</p>

<hr />

<p>NEW YORK, N.Y. — Today, the FBI revealed that the major corporation attacked by hackers working for Belize, is Sone Corp., a entertainment powerhouse. The stock briefly dropped 5%, but closed the day with a minor increase.</p>

<p>Anonymous source within the government have revealed that they are completely confident that Belize is completely behind this, and other recent attacks. “There will be a price to pay for attacking American businesses - the administration is reviewing the options in response to this clear act of cyber-terrorism” - the source refused to be identified as they weren’t authorized to speak on the subject.</p>

<hr />

<p>With the media in a frenzy, the President was forced to make a statement, formally accusing Belize of attacking not only Sone Corp, but several smaller attacks over the last six months. The tone was harsh, there were promises of severe economic penalties. The United States would not tolerate such attacks.</p>

<hr />

<p><em>Six months earlier…</em></p>

<p>In a small bar off of the Las Vegas strip, a small group of pentesters seek refuge from the chaos that is DEF CON. After a few rounds of top-self whiskey, one has a bright idea…</p>

<p>“I’d bet if we spent a few dollars to get a VPS in China, hacked the first military server we can - pull off a few attacks, within a few months we could get the U.S. Government &amp; some of these big security contractors to label us as a nation-state actor.”</p>

<p>“Nah, I’m sure they get the NSA TAO involved to verify before pointing fingers.”</p>

<p>“$1,000 says it’ll work.”</p>

<p>“You’re on.”</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Orwellian Justice]]></title>
    <link href="https://adamcaudill.com//2014/12/03/orwellian-justice/"/>
    <updated>2014-12-03T16:18:00-05:00</updated>
    <id>https://adamcaudill.com//2014/12/03/orwellian-justice</id>
    <content type="html"><![CDATA[<p>A few hours ago, a Grand Jury in New York decided that the video-taped murder of an unarmed man didn’t justify a trial to determine if those, clearly seen and identified, who killed him had broken any laws. The man I speak of is <a href="https://en.wikipedia.org/wiki/Death_of_Eric_Garner">Eric Garner</a>. What struck me immediately, was the Orwellian undertones that this event has.</p>

<h3>Grand Juries &amp; Time Control</h3>

<blockquote><p>He who controls the past controls the future. He who controls the present controls the past.</p><footer><strong>George Orwell</strong> <cite>1984</cite></footer></blockquote>


<p>In criminal cases brought before a Grand Jury to determine if there’s enough evidence that a person is guilty of a crime to justify being charged, the person that controls the past, is the prosecutor. Their responsibility is to present the evidence to the jury - documentation, photos, videos, testimony, etc. - to get them to bring charges, if there is enough to show guilt.</p>

<p>The show isn’t ran by the courts, as is the case with other parts of the justice system, but instead by the prosecutor, who has control over what the jury sees and hears. It is this power, this control over evidence, this control over the past, that allows them to, when they so choose, to take on an alternate role - defender.</p>

<p>In 1985, <a href="https://en.wikipedia.org/wiki/Sol_Wachtler">Sol Wachtler</a>, the Chief Judge of the New York Court of Appeals rather famously mused that a prosecutor could indict a ham sandwich if they wanted to - and based on numbers from the federal grand jury system, that seems very accurate. In 2010, federal grand juries returned indictments in 162,000 cases - and declined to do so in only 11.</p>

<p>For those that are outside of the law enforcement community, it’s clear that the grand jury is just a rubber stamp process. Yet, for those inside the system, its use is more delicate, more finessed - more directed. It’s easy for a prosecutor to get a jury to indict someone - but as recent events have shown, with enough time, they can take undeniable evidence and through careful tactics, sabotage their own case. Preventing the accused from being charged at all.</p>

<p>Suppress useful evidence, call questionable witnesses, present confusing and unclear information, question the integrity of everything presented - there are so many options available to ensure that the jury won’t see clear guilt. With some time, the prosecutor becomes the master of the past, painting the picture that he wants the jury to see - free from disagreement or dissenting views.</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p>Grand juries have enormous independence on paper, but almost impossible to exercise in practice. All evidence seen via prosecutor&#39;s lens.</p>&mdash; matt blaze (@mattblaze) <a href="https://twitter.com/mattblaze/status/540238535274418176">December 3, 2014</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<h3>Just a little doublethink…</h3>

<p>How much time, how many confusing statements, how many character assassinations does it take before a jury can see, with their own eyes, a murder - and by the skill of a great <del>defense attorney</del> prosecutor, accept that while they saw a murder, a murder didn’t occur?</p>

<p>Or, in this case, not only didn’t a murder occur - no crime at all occurred. He was murdered, and he wasn’t.</p>

<p>It’s important to remember, this wasn’t a open trial - this was simply to determine if charges should be brought at all. In this case, the decision was that there will be no charges, no trial to determine if the killing was justified, no attempt at justice for the dead. Never will a real jury, in a court of law, hear the case and be able to make a determination based on the evidence - that determination was already made by the prosecutor.</p>

<p>A process that is a rubber stamp to those on the outside, becomes a free-pass for those on the inside of the system.</p>

<h3>…and justice for all.</h3>

<p>There is no justice in this case, nor illusion of justice. No thinly veiled farce of a trial to appease the masses. Nothing.</p>

<p>I must wonder, how much longer before such cases won’t even see the “light” of a secret grand jury, and just die on a prosecutors desk. When the prosecutor works to defend the accused - only when the accused is part of their system of course - why bother with the show, why even pretend to try. Justice isn’t their goal, protecting those on the inside, those that enforce is the goal.</p>

<p>Control, intimidation, and fierce reprisal to any that dare resist is the hallmark of enforcement today - “justice” is granted to the favored, retribution to the rest. Enforce and control has become the unspoken replacement to “protect and serve” - a statement that meant little, and now serves as an insult to those, that for one reason or another, find themselves outside of the “favored” group.</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p>Crimes committed by LEOs should be prosecuted by a special prosecutor; the risk &amp; impact of them acting as a defense attorney is too great.</p>&mdash; Adam Caudill (@adamcaudill) <a href="https://twitter.com/adamcaudill/status/540249660947181568">December 3, 2014</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>Who enforces against the enforcers? Who can be objective when dealing with a person inside the system that supports them? For any chance at justice, when a member of law enforcement is accused of a crime, it should be an outside prosecutor that brings the case to the grand jury. While there’s still risk of the prosecutor acting more as a defender, by appointing a special prosector from outside the normal system, there’s at least some chance that the grand jury will see the unaltered truth. Then, maybe, there will be a chance for real justice.</p>

<p>Change to the justice system in the United States is needed on many fronts, racism is rampant, intimidation and coercion have become normal, police are more militarized than the military, and the use of excess force is justified by any excuse. Killing a person should be the last, most desperate line of defense - not something excused by the slightest feeling of discomfort. Though as long as the grand jury can so easily act as a free pass, this change will never be achieved.</p>

<p>Things like body cameras, which the federal government is now supporting, are a step in the right direction. They eliminate questions, and allow the public to see, with their own eyes, what happens. But, no matter how many cameras are deployed to monitor law enforcement activity, if grand juries ignore evidence that’s inconvenient to a prosecutor’s goal, no crimes will be averted, no pointless deaths prevented.</p>

<p>The system is broken. Only by a feat of doublethink can anyone see anything else.</p>

<p><em>To my friends in law enforcement:</em> Please don’t take this as an attack against you. You have a hard job, and at times it’s certainly dangerous. But the system is broken, you may think my view is wrong - but your perspective is likely just as tainted. To those on the outside, to those that don’t have the benefit of being protected by the system - too often feel oppressed by the system, punished unfairly and in excess of reason. Please understand that there is a perspective that you, likely, can’t see.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speaking at SC Magazine Congress]]></title>
    <link href="https://adamcaudill.com//2014/11/23/speaking-at-sc-magazine-congress/"/>
    <updated>2014-11-23T17:12:00-05:00</updated>
    <id>https://adamcaudill.com//2014/11/23/speaking-at-sc-magazine-congress</id>
    <content type="html"><![CDATA[<p>Last week <a href="http://brandonw.net/">Brandon Wilson</a> and I gave the lunch keynote at the <a href="http://congress.scmagazine.com/page.cfm/link=16">SC Magazine Congress</a> event in Chicago. It was a fun, more executive level event - a big thanks to Eric Green and team. The talk was mostly an executive overview of what was discussed at <a href="https://adamcaudill.com/2014/10/02/making-badusb-work-for-you-derbycon/">our DerbyCon talk</a>, with some updates, and some insights.</p>

<p>Here are the slides, and a rough transcript from the event:</p>

<iframe src="https://adamcaudill.com///www.slideshare.net/slideshow/embed_code/41900274" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p><em>(This is based on the speaker notes - so it doesn’t include the discussion and other bits that were said)</em></p>

<p><strong>Slide 2:</strong> (Adam) Hi, I&#8217;m Adam Caudill, I&#8217;m here today with Brandon Wilson, and we are here to talk about some research that we&#8217;ve been working on. We will be giving you some background information on BadUSB, showing it to you in action, and talking through the real risks.</p>

<p><strong>Slide 3:</strong> (Adam) USB devices are truly ubiquitous - they are all around us. We all use them on a daily basis, but as is true for most technologies, the things that make our lives easier can be turned to attack us. This is a clear case of a technology that was designed to make life easier, but thanks to designers and implementers not fully understanding the potential for abuse, they have opened a door to attack vectors that most people don’t realize exists.</p>

<p>That USB is so common is both a blessing and a curse – from a convenience perspective, it’s great that USB devices and things that support USB are everywhere, but from a security perspective, there are costs, there are risks. Risks that few people realize that they need to be worried about.</p>

<p><strong>Slide 4:</strong> (Adam) BadUSB - the ability to take a seemingly harmless device and turn it into something evil, has been getting a lot of attention lately. We are here to talk about our findings, other research that&#8217;s going on, how this research can be extended, and what it means for those trying to defend against attacks.</p>

<p><strong>Slide 5:</strong> (Adam) First, lets talk about what BadUSB isn&#8217;t - it&#8217;s not an exploit, it&#8217;s arguably not even a vulnerability. It&#8217;s not a flaw in a device, or an oversight in a protocol. BadUSB, really, part behavior by design, and part carelessness on the part of device manufacturers.</p>

<p>BadUSB was first publicized by the Security Research Labs team from Germany, their work started with looking into a way to reprogram thumb drives to perform data processing - this led them to realize that the technique they intended to use to add features, could also be used by attackers.</p>

<p>Their talk at Black Hat USA was the first time many people heard about the possibility for such issues. It&#8217;s their talk, and their decision to limit the details they released, that led us to change directions in some research we were doing, and get more details and code out to defenders.</p>

<p>Before we go too much further, lets talk just a little about USB, things most people don’t know about it.</p>

<p><strong>Slide 6:</strong> (Brandon) When BadUSB was first introduced, the focus was on a design aspect of USB - something that has been used by legitimate designs for years, composite devices. In short, a composite device is a USB device that has multiple interfaces, or profiles, each exposing a different type of device. The classic case for BadUSB is a thumbdrive that is also a keyboard.</p>

<p>This isn&#8217;t a vulnerability though - this is perfectly compliant with the USB specification. Devices are allowed to do this, it&#8217;s intended behavior and by itself is not a bad thing. Of course, this doesn&#8217;t just apply to being a mass storage device and a keyboard - NICs, printers, USB display adapters, webcams, and so on - any combination is possible.</p>

<p>So, for this part at least - it&#8217;s a feature, a feature that can be abused.</p>

<p><strong>Slide 7:</strong> (Brandon) To turn a thumbdrive into something more, it requires updating the device’s firmware - the code that resides on the device and makes it function. Many people see thumbdrives as just a data storage device, without realizing that there&#8217;s a programmable controller inside.</p>

<p>These controllers are often user updatable, meaning that with only some software, anyone can perform the update. Why would the manufacturer want to let people update the firmware on a flash drive, you might ask? Well, there can be bug fixes, improvements to how it communicates with the NAND memory inside, better bad block management, etc. Where this becomes a problem though, is that some of the largest controller vendors don&#8217;t enforce signed updates. So not only can any user update them, they can update them with any code they choose.</p>

<p>So this, the fact that they are selling chips that don&#8217;t have any security considerations at all, is what turns USB&#8217;s feature of allowing composite devices into a real attack vector.</p>

<p><strong>Slide 8:</strong> (Brandon) Using firmware as an attack vector is far from new though, it&#8217;s been done for years - though I don&#8217;t believe that most people realize that so much research has been done that shows how weak many devices are.</p>

<p>We’ll get into some examples a little bit later, but people were reprogramming Apple keyboards to appear as other devices years ago, and a decade ago I was making graphing calculators show up as flash drives, so this is by no means new.</p>

<p><strong>Slide 9:</strong> Here is a picture of a typical thumb drive &#8211; there is the USB port of course, then that square controller chip which is the “brain” of the device (and what runs the firmware that makes the drive work), and then the NAND flash memory on the far left.</p>

<p>There are different vendors involved here &#8211; NAND comes from one company, controller from another, sold under another name, etc. They’re essentially just putting the parts together, so there are a lot of different combinations out there.</p>

<p><strong>Slide 10:</strong> (Brandon) Let&#8217;s take a few minutes to talk about firmware&#8230;</p>

<p>For this talk, so we can have specific examples, we are going to talk about the Phison family of controllers - Phison is the largest maker of controllers used in thumbdrives, so that&#8217;s why we are picking on them.</p>

<p>In this case, the device has a small boot image built into the controller itself, which is responsible for loading the firmware from the NAND chip and executing it - through the use of special applications on a PC, users can update the firmware with different, or modified versions. This is something most users know nothing about - but it&#8217;s there.</p>

<p><strong>Slide 11:</strong> (Brandon) Devices with updateable firmware aren&#8217;t inherently evil of course, but the question is, does it use signed updates. Which is to say, do the updates include a cryptographic signature, based on a protected private key that only the device manufacturer has access to. If the answer to that is no - the devices doesn&#8217;t validate the origin of updates, and it could be a target for a BadUSB style attack.</p>

<p>To be secure, devices need to validate all updates, using a non-updatable public key. This is the only way to ensure that the firmware is from a legitimate source, and not from some attacker. If the public key were updateable, then there&#8217;s the risk that with physical access, or by taking advantage of a flaw, the key could be changed to an attacker-controlled public key - making it impossible to restore the device to stock firmware.</p>

<p><strong>Slide 12:</strong> (Brandon) Even <em>if</em> a device uses only signed updates, that&#8217;s not a guarantee that it&#8217;s safe. There are many ways that an update system can fail - and it&#8217;s important to remember that once these systems are developed, they tend to not be updated, so they are often using old or even obsolete technologies.</p>

<ul>
<li><p>Weak signing keys. Texas Instruments found this out the hard way, when their 512-bit RSA signing keys for their graphing calculator line were factored and publicly released, allowing anyone to release signed updates.</p></li>
<li><p>Verification failures. There have been some systems that use signing - but never bother to actually validate it.</p></li>
<li><p>Implementation failures. In one case, a system used string comparison to check if the hashes match - which worked great until there was a null byte in the hash (which is also used to indicate the end of a string in memory). This allowed attackers to steal a valid signature, with only a partial hash collision.</p></li>
<li><p>Exploitable code. If the signature check cannot be defeated, and I’ve had to do this, there are often ways to bypass it completely by taking advantage of vulnerabilities in poorly-written code.</p></li>
</ul>


<p><strong>Slide 13:</strong> (Brandon) To take advantage of all of these possibilities, an attacker has to perform some significant reverse engineering. Most of the products that are likely to be targeted, have little or no documentation - there are no spec sheets, no SDKs. It requires reverse engineering the firmware, and using that to document and understand how the hardware works, and then use that to identify how to add or change functionality.</p>

<p><strong>Slide 14:</strong> (Brandon) On thumbdrives, being able to update firmware opens the doors to many things, not just the composite device attacks, but also changes in device behavior that makes it all but impossible to know if the device is behaving in a trustworthy way.</p>

<p><strong>Slide 15:</strong> (Brandon) Thumbdrives are often used to transport sensitive information - but with modified firmware, it might not be doing what you think it is.</p>

<ul>
<li>Duplicating data to a hidden area for later retrieval</li>
<li>Instead of deleting files, copying it to a hidden area</li>
<li>Altering file contents when written - imagine writing a document to a drive, and later opening it to find that it says something else?</li>
<li>Inserting malware into executables. The first time an executable is read (by antivirus software), it appears legitimate, but the second time it’s read (for execution), it’s completely different.</li>
</ul>


<p>You can see where we are going here - once you can no longer trust the firmware of a device, you can&#8217;t trust that anything it does or tells you.</p>

<p><strong>Slide 16:</strong> (Brandon) A drive could also be modified to defeat forensic analysis. It&#8217;s common to connect a thumbdrive to a write-blocker to protect it - but a write-blocker can&#8217;t protect against the firmware.</p>

<p>Something we designed, but aren&#8217;t releasing, is modified firmware that expects to receive a special command from the PC it&#8217;s connected to - if that command isn&#8217;t received within the first few seconds, it then proceeds to erase the NAND, and destroy the firmware. Rendering the device unusable.</p>

<p>Within seconds of connecting it to a machine that doesn&#8217;t pass the secret command, the drive is toast. With this type of firmware, the only way to dump the data safely becomes dumping the NAND directly, without allowing the controller to have power. And by protecting the NAND by coating it in a hard substance like epoxy, even dumping the NAND becomes problematic.</p>

<p><strong>Slide 17:</strong> (Brandon) So, with all of that said - let&#8217;s take a look at BadUSB in action, with some of the code that we&#8217;ve made publicly available. After we see it in action, we&#8217;ll talk about where this research can go, and try to help you understand what the real risks are.</p>

<p><strong>Slide 18:</strong> (Brandon) This first demo is just the classic “show up as a keyboard and type out a bunch of commands automatically” scenario, which has been in the wild for many years through other devices such as the USB Rubber Ducky device, development boards, etc.</p>

<p>What this drive will do is type out a one-line PowerShell command that downloads an executable from a server and executes it. This executable will open a shell so others can connect and do various bad things.</p>

<p><strong>Slide 19:</strong> (Brandon) Next up, we&#8217;ll show you a patch to the existing firmware to add a new feature for data exfiltration - a hidden partition that&#8217;s only accessible via the right events.</p>

<p>The drive is divided in half, the first half of the drive shows up when you insert the device - if you look at it in &#8220;Disk Management&#8221; in Windows, you&#8217;ll only see half the size, format it - half the size, query the device - same thing, half the size. Everything looks and acts normal. Format it, do whatever you want. This is hidden entirely in firmware, so the host device doesn&#8217;t have a way to see what&#8217;s going on unless the right bit is flipped.</p>

<p>Until you eject the drive - not using the &#8220;safely remove hardware&#8217; option, but eject - after a few seconds it&#8217;ll re-enumerate and mount a hidden partition. You can dump whatever data you like here, and either unplug the drive, or hit eject again to get back to the first, original partition a few seconds later.</p>

<p>This is a really simple way to hide data on a drive that appears to be empty. I wouldn&#8217;t try to use it to get past the NSA, but it&#8217;ll pass most checks.</p>

<p><strong>Slide 20:</strong> (Brandon) Many drives support a mode that allows the contents to be protected by a user supplied password - until you enter the password, you can&#8217;t see the content of the drive.</p>

<p>We&#8217;ve made a very simple patch to the firmware that changes the way that the password change function works.</p>

<p>Normally you wouldn&#8217;t be able to access the contents of the drive without knowing the user&#8217;s password. With a simple change, we can change the password change function, so that it doesn&#8217;t verify that the old password is right - so you can take a drive that has password protected content, apply our patch, and change the password to something you know, without ever knowing the original password.</p>

<p>This shows how a simple change in unsigned firmware can drastically change the security profile of the device.</p>

<p>So we&#8217;ll take a drive, where I don&#8217;t know the password, and set the password to something new.</p>

<p><strong>Slide 21:</strong> (Brandon) – Here’s Adam to talk about where this research can go, and the implications and impacts of BadUSB.</p>

<p><strong>Slide 22:</strong> (Adam) So far, all we&#8217;ve been talking about is thumbdrives - but that&#8217;s just the beginning. How many people here knew that some keyboards and mice have user updateable firmware?</p>

<p>In 2009, K. Chen demonstrated an attack against Apple keyboards, it used the same technique behind BadUSB. Update the device with malicious firmware, have it open a reverse shell, win.</p>

<p>This was from 2009, and what we are seeing with BadUSB is just another take on the same issue.</p>

<p><strong>Slide 23:</strong> (Adam) This issue isn&#8217;t unique to thumb drives - many different devices are subject to the same issues. So many devices that are routinely and thoughtlessly connected to computers can be updated with malicious firmware.</p>

<p>Even better - many of these devices are installed in laptops, and connect over USB internally. So it&#8217;s possible that even internal peripherals could be attacked. The USB hubs integrated into motherboards are even a risk.</p>

<p>Now, I don&#8217;t say this to make you paranoid, but so you&#8217;ll have a better understanding of your attack surface. These devices are all around us, and any time one of them isn&#8217;t in our control, it could be reprogrammed by an attacker.</p>

<p>Keyboards, mice, printers, webcams, touchpads, Bluetooth adapters, SD card readers, USB hubs - almost anything that connects over USB could be attacked this way. The problem is, nobody knows what is vulnerable.</p>

<p>Devices aren&#8217;t labeled with what controller they use, and even for the same brand and model of a device, the controller used can vary. This makes it nearly impossible to determine what is and isn&#8217;t at risk to this type of attack.</p>

<p><strong>Slide 24:</strong> (Adam) Shortly after we released our code, I got a call from a reporter at Wired asking for more information. One of the topics that came up is, could this be used to build a firmware based worm.</p>

<p>After the question was asked, I sat in silence for a moment before responding - this is not only something we had thought of, but Brandon and I had spent hours discussing the possibility. At first, it was because we thought it could be the basis of a great talk - but then, it turned into a discussion of risks, was such research too risky.</p>

<p>I finally answered - yes, it&#8217;s possible, and we know how to do it.</p>

<p>This is the worst case scenario for BadUSB, a worm that infects the firmware of thumbdrives, and possibly other devices. Plugging an infected device into a machine could be enough to infect it, then it will spread from machine, to devices, to other machines. The devices could be made to be nearly impossible to clean - format the thumbdrives all you want, that won&#8217;t get rid of malware in the firmware. This is a scenario we hope to never be seen in the wild, but with an attacker with enough resources, it&#8217;s very possible.</p>

<p><strong>Slide 25:</strong> (Adam) This is clearly a problem, and very much a risk, on multiple fronts for secure environments - so how is this being addressed? For the most part, it isn&#8217;t. For me, there&#8217;s a striking similarity between the way these manufacturers are reacting to this, and the way ICS manufacturers responded to security issues prior to Stuxnet. They ignored the problem until something so dramatic, so important happened, that they couldn&#8217;t ignore it any longer.</p>

<p>I expect it&#8217;ll be the same with BadUSB - at some point there will be an event that drives the point home that this issue has to be addressed at the root of the problem - the massive number of devices with insecure firmware updates.</p>

<p><strong>Slide 26:</strong> (Adam) As Brandon said earlier, to pull of any of these attacks requires some significant reverse engineering work - if you have the right experience, it&#8217;s really not that hard. It does take quite a bit of time though. So, these are practical attacks, but there aren&#8217;t that many people that can do the work.</p>

<p><strong>Slide 27:</strong> (Adam) This is one of the most common questions, and the hardest to answer. Some of these attacks can be more easily performed with other hardware - the pre-programmed keyboard that opens a shell for example, can be done with a USB Rubber Ducky, an easy to acquire pen-testing tool that looks just like a thumbdrive, but is actually much more.</p>

<p>With USB development boards readily available, many things that are possible with BadUSB, are easier with better understood, well documented hardware. So, if an employee plugging in an unknown thumbdrive and it turning into a keyboard is a real risk in your environment - then BadUSB isn&#8217;t the problem you should be worried about.</p>

<p>Now, things like the integrity of data on the device, the modifications to how a thumbdrive operates, that&#8217;s a different issue, and one that&#8217;s harder to protect against. If the drive is ever out of your control, you can&#8217;t know if it&#8217;s trustable. I hate FUD as much as anyone, but if you have a device that anyone can update to operate in ways that you don&#8217;t want - if you ever lose control of it, you can&#8217;t know if it&#8217;s working for you or an attacker.</p>

<p>So, what&#8217;s the risk? It depends on how much people want what you have.</p>

<p><strong>Slide 28:</strong> (Adam) How many people here have policies that allow employees to use their own keyboard or mouse? OK, how many people think this happens even if it&#8217;s against policy?</p>

<p>When most people talk about BYOD policies, they aren&#8217;t thinking about the devices that connect to computers. But thanks to BadUSB, this is something that all companies should be thinking about - a user bringing in that Razer mouse they love so much, could actually be introducing a new attack vector, thanks to the updateable firmware.</p>

<p>I&#8217;m not going to recommend that companies ban all outside devices - but companies should be very aware of not just what&#8217;s on their network, but what&#8217;s connected to the things on their network. You can&#8217;t protect against what you don&#8217;t know about.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On NSA-Proof Security]]></title>
    <link href="https://adamcaudill.com//2014/10/19/on-nsa-proof-security/"/>
    <updated>2014-10-19T18:51:00-04:00</updated>
    <id>https://adamcaudill.com//2014/10/19/on-nsa-proof-security</id>
    <content type="html"><![CDATA[<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p><a href="https://twitter.com/KimZetter">@KimZetter</a> We need to distinguish between &quot;proof against NSA dragnet&quot;, &quot;proof against NSA PRISM&quot;, and &quot;proof against NSA TAO&quot;. <a href="https://twitter.com/runasand">@runasand</a></p>&mdash; zooko (@zooko) <a href="https://twitter.com/zooko/status/512264453228744704">September 17, 2014</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>For a long time, “military grade encryption” has been a red flag for snake oil, over-hyped, under-performing garbage, so much so that it’s become a punchline. Anytime that phrase is seen, it’s assumed that the product is a joke - quite possibly doing more harm than good.</p>

<p>Since Snowden dropped his document cache, opening the world’s eyes to what’s been going on behind the scenes at what is likely the world’s most sophisticated attacker, NSA-Proof has become the new “military grade encryption” - marketing hype leading to instant ridicule by industry insiders. This phrase isn’t as simple though - the NSA isn’t a single dimensioned threat. So when talking about defenses, you have to think about not just avoiding the NSA, but avoiding the various attack classes they leverage.</p>

<h3>Fighting NSA Programs</h3>

<p>When people talk about resisting the NSA, what exactly does that mean? As the NSA runs many programs, we have to look at the programs to see what could (or couldn’t) be real resistance.</p>

<p><strong><a href="https://en.wikipedia.org/wiki/Tempora">Tempora</a></strong> (and similar projects) that tap backbone links, siphoning data en mass for later processing. Projects like this gather as much as possible, with no concern for who’s data they are looking at.</p>

<p>These efforts are passive, they see what’s going over the fiber, but without changing it. So encryption, even opportunistic (which I’m <a href="https://adamcaudill.com/2014/02/25/on-opportunistic-encryption/">really not a fan</a> of), prevents them from getting useful data. So TLS is NSA-Proof, from this very specific angle - it prevents them from <strong>passively</strong> collecting this data.</p>

<p><strong><a href="https://en.wikipedia.org/wiki/PRISM">PRISM</a></strong>, the infamous project whose exact role and function is still being debated. Metadata is king, <a href="http://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata/">metadata kills</a>. Metadata is easier to understand in bulk, and far easier to process than actual content for most (if not all) types of communication. Once you have enough of it, it’s far more valuable than the content it went with.</p>

<p>Want to protect against PRISM? Easy, kill all of the metadata. For a service provider, the less they know, the less they can be forced to hand-over. Email for example, is loaded with useful metadata, data that’s easily mined and correlated. Services and protocols that are being developed to be PRISM resistant are doing so by encrypting as much as possible, and minimizing the exposed metadata.</p>

<p>So, NSA-Proof is possible here as well, in a very specific angle. It’s harder to protect against than something like Tempora, but still doable with the right design.</p>

<p><strong><a href="https://en.wikipedia.org/wiki/Tailored_Access_Operations">TAO</a></strong> What about TAO, the NSA’s version of the special forces? Guarding against wide-scale NSA data collection is one thing, targeted activities are a different story.</p>

<p>I once suggested a <a href="https://adamcaudill.com/2013/09/06/making-android-nsa-proof/">method for making Android NSA-Proof</a> (it involves thermite, so it’s fun too!), and if you are targeted by TAO, that’s probably the best bet. There are ways you can make their job harder, but as long as they can figure out where you are, there’s always the <a href="http://arstechnica.com/information-technology/2013/12/inside-the-nsas-leaked-catalog-of-surveillance-magic/">implant</a> option.</p>

<p>So can you be NSA-Proof from TAO? Probably not. You can make your odds better, but if they are willing to put the effort in, sooner or later they’ll win unless you are very well funded, and willing to take extreme measures.</p>

<h3>Marketing Hype</h3>

<p>Many journalists use similar terms, ‘NSA proof’, ‘NSA resistant’, ‘thwarting the NSA’, and a hundred others. While there’s a good chance it’s just more snake oil, it’s possible that there may be <em>some</em> truth to it.</p>

<p>When dealing with an adversary like the NSA - you have to consider which part of the NSA. They are after everyone with mass data collection, which is something that can be fought - with a high likelihood of success. Though as the the targeting becomes more focused, the odds start dropping. Once TAO is involved, only the best funded have any hope of resisting.</p>

<p>If a service claims to be ‘NSA-Proof’ - it could be true, to a limited extent. Such claims really need to be qualified; if a service makes this kind of claim, they should provide information of which programs (or program types) they are trying to resist.</p>

<h3>So, what does NSA resistance actually require?</h3>

<p>This, obviously, isn’t an easy question and depends very much on the nature of the service. Though there are a few high-level things to look for:</p>

<ul>
<li>Strong, non-NSA backed crypto primitives. I’m a big fan of <a href="http://nacl.cr.yp.to/">NaCl</a> because it’s fast, constant-time, secure crypto that doesn’t rely on anything backed by the NSA. To make it easier to use, it’s made portable (and extended) in <a href="https://github.com/jedisct1/libsodium">libsodium</a>. I won’t promote anti-NIST FUD, but some things should be questioned, such as the NIST ECC curves.</li>
<li>Minimal metadata. The amount of information that can be extracted from messages should be at a minimum. Anything that’s exposed (username, user ID, public keys, etc.) can be used when collected en mass to begin mapping relationships and undoing the veil of anonymity.</li>
<li>Encrypt everything in transit. As with metadata, anything in the clear going over the network can be captured, stored, analyzed - and in targeted cases, altered in various ways. Using TLS is a great start to this, as it removes the option for simple passive monitoring, though it shouldn’t be assumed to be enough. Active attackers can man-in-the-middle the server, passing a forged/stolen certificate. Certificate pinning, and additional layers of encryption help protect against these attacks.</li>
<li>Server knows as little as possible. The more the server knows, the more the provider(s) can divulge - either by court order, or by more clandestine means. Even the simplest HTTP server logs can provide valuable information to such an attacker, especially when combined with other data sources.</li>
<li>Encrypt everything in storage. When at rest, everything should be encrypted - if a device is compromised, it should reveal as little as possible. By encrypting everything based on the user’s password, only the user is able to access the data (though may be by force).</li>
<li>Hide everything. The CIA at least once used a weather application to <a href="http://www.theguardian.com/world/2014/jul/09/germany-arrest-second-spy-accused-us-cia">hide a communication system</a>; it was only available when looking up weather for a certain city. Such techniques make it harder to spot the use of secure communication tools. This may seem a bit extreme, but there are good reasons to do it.</li>
</ul>


<p>There’s more of course, these are just a few high points. Defending against an adversary that has a huge budget, doesn’t respect international law, has a rubber stamp court, and some of the best technical talent in the world requires - special - measures. Of course, the NSA isn’t the only player; it goes beyond <a href="https://en.wikipedia.org/wiki/Five_Eyes">Five Eyes</a>, every major power engages in such activity to some extent.</p>

<p>If you can provide a reasonable degree of protection against PRISM &amp; <a href="https://en.wikipedia.org/wiki/United_States_Foreign_Intelligence_Surveillance_Court">FISC</a>, then you can expect to have equal odds with other players using the same attacks. Will it actually work? Who knows; there’s a lot that can go wrong, a lot of mistakes that can be made, so many ways a good intentioned developer can turn a secure system into a thin facade that offers no protection. The list above is a starting point, not the final requirements.</p>

<h3>Can it really be achieved?</h3>

<p>Achieving real resistance to illegal surveillance is a huge challenge, but at least some degree of success can be had by taking simple measures. Ensuring that everything possible is encrypted, that all network traffic is encrypted, and the like will make it far more of a challenge for an attacker.</p>

<p>TAO-level resistance probably isn’t realistic, but lower levels are a real option, and should be pursued whenever possible. While calling anything ‘NSA proof’ should be seen as a red flag, there are real techniques to resist the NSA and other agencies that seek to invade the privacy of the world.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A backdoor by any other name...]]></title>
    <link href="https://adamcaudill.com//2014/10/17/a-backdoor-by-any-other-name/"/>
    <updated>2014-10-17T17:14:00-04:00</updated>
    <id>https://adamcaudill.com//2014/10/17/a-backdoor-by-any-other-name</id>
    <content type="html"><![CDATA[<p>Yesterday James B. Comey, the Director of the FBI continued the propaganda campaign against encryption with a fresh batch of lies and misdirection. The FBI has been pushing to add backdoors to cryptosystems around the world - no matter how many people they put at risk in the process. Starting in the 1990’s, the FBI has been at the forefront of trying to make their job easier by endangering the world.</p>

<p>What Comey did today was to lay the foundation for a renewed push for a new, expansive, <a href="https://en.wikipedia.org/wiki/Communications_Assistance_for_Law_Enforcement_Act">CALEA</a> type law that would give <em>governments</em> access - via court orders or surreptitiously, to all of your data. In 2013 they were pushing for <a href="https://freedom-to-tinker.com/blog/felten/calea-ii-risks-of-wiretap-modifications-to-endpoints/">CALEA 2</a>, which would have expanded their ability to secretly access your data in a massive way. Thankfully the Snowden documents put an end to that - at least for awhile.</p>

<p>I use the term governments instead of specifying the US Government very intentionally. Under CALEA, certain systems must be compliant to be sold in the US - so companies add support, and then ship them all over the world instead of supporting two versions. So the FBI’s desire to have easy access to anything they want puts people around the world at risk. But surely nobody would abuse this, right?</p>

<p>In 2004, thanks to support for this type of “lawful intercept” support, <a href="https://en.wikipedia.org/wiki/Greek_wiretapping_case_2004%E2%80%9305">Vodaphone in Greece was hacked</a> - tapping top government and civil leaders. Who did it still isn’t known, but many suspect that the US Government was behind it. Then there’s <a href="https://firstlook.org/theintercept/2014/05/19/data-pirates-caribbean-nsa-recording-every-cell-phone-call-bahamas/">SOMALGET</a>, the NSA program to collect all calls made in the Bahamas. The DEA was given access to their phone systems for the purposes of “lawful intercept” - again, a CALEA compliant setup, which was then used to collect everything they were able to get. These are just two high profile examples, there are many cases where researchers have found flaws in these systems, making them easy prey.</p>

<p>For years, it’s been made clear that such backdoors were disasters - and it’s not just CALEA compliance either. There’s the infamous <a href="https://en.wikipedia.org/wiki/Clipper_chip">Clipper chip</a> which would encrypt voice calls, but allow the government to easily listen in - but thanks to fatal flaws, anyone else could as well.</p>

<p>Thanks to this, pretty much everybody agrees that backdoors are a bad idea, so the FBI had a great idea - call it something else!</p>

<h3>A rose by any other name…</h3>

<p>Comey, deciding that he shouldn’t have to deal with reality, and that the best way to address the public was misdirection:</p>

<blockquote><p>We aren’t seeking a back-door approach. We want to use the front door, with clarity and transparency, and with clear guidance provided by law.</p></blockquote>


<p>And by “front door”, he means some new backdoor into everything.</p>

<p>He wants the ability to decrypt data, without having to get information from the suspect; which means adding a backdoor to systems, to allow them - and likely many others to get in. This is no different than the disastrous Clipper chip idea.</p>

<p>The FBI is trying to misdirect the public, lead them to believe in some magical, secure backdoor that is abuse-proof. But when such an idea is being pushed by an organization that has so much abuse and illegal activity in its history - should anyone trust what they say?</p>

<h3>Putting enforcement first</h3>

<p>At one point Comey said something that I found shocking:</p>

<blockquote><p>Are we so mistrustful of government—and of law enforcement—that we are willing to let bad guys walk away&#8230;</p></blockquote>


<p>If you read the US Constitution, this is answered for him - in many places it is made clear, it’s better to let a criminal walk free than to infringe on the rights of the innocent. Preserving the rights of the people trumps everything.</p>

<p>For law enforcement, this isn’t about justice, or the rule of law - this is about their power, their ability to get what they want, when they want it. If they put people in harms way in the process, that’s a price they are willing to let the public pay.</p>

<h3>Only one government?</h3>

<p>In the discussions about this, one major point keeps being missed - this isn’t just about the US Government, but about the governments all around the world. If companies are forced to add backdoors to products for the US market, you can bet that same backdoor will be shipped to every country they work in.</p>

<p>So the danger is global - but as this is something that can be used for intelligence, as CALEA has been used for in the past, I’m sure this fact hasn’t escaped the attention of planners at the NSA. For the NSA, a CALEA 2 style law would give them easy access to expend their already vast - and illegal - collection operations. It would be a dream come true.</p>

<p>There’s also another international component to this issue - many major tech companies operate in several countries, making them subject to local courts. What happens when they receive a court order for access to this backdoor and a gag order, to prevent them from talking about it? Suddenly American data will be at risk from foreign powers.</p>

<p>There are so many issues opened up when backdoors are added, that one could talk for days and still not cover all the ways it could be abused.</p>

<h3>Lies and mistrust</h3>

<blockquote><p>Perhaps it’s time to suggest that the post-Snowden pendulum has swung too far in one direction—in a direction of fear and mistrust.</p></blockquote>


<p>It seems that Comey is surprised that people don’t trust the government, after lies, deception, and violations of law are revealed. How shocking.</p>

<p>The US Government has failed to uphold the Constitution, and technology companies have stepped up to provide a level of protection in the face of a Government that has ignored its obligations. I’m sure that the FBI would love to go back the old days - where we assume the government is doing the right thing while secretly violating the Constitution and ignoring international law. Anything to give them more power and control.</p>

<h3>The New Crypto Wars</h3>

<p>In the 1990s, the first crypto war was fought, and many believed that the public had won. What we are seeing is, without question, that a new war has started. Apple’s decision to change the way they encrypt phones wasn’t what started it - the writing had been on the walls for some time, it was just the ammunition they were waiting to go on the attack.</p>

<p>Those that work with cryptography daily fighting to protect users, while the government is busy trying to protect what they want, over the rights and protection of the people. Expect it to get ugly.</p>

<p>It’s going to be a fight, and what happens in the next year or two will be critical. If the FBI wins, privacy dies.</p>

<p><em>(Sorry for the ranty nature of this post - it’s an issue I feel strongly about, and something that we must take action on.)</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On The Ethics of BadUSB]]></title>
    <link href="https://adamcaudill.com//2014/10/03/on-the-ethics-of-badusb/"/>
    <updated>2014-10-03T12:28:00-04:00</updated>
    <id>https://adamcaudill.com//2014/10/03/on-the-ethics-of-badusb</id>
    <content type="html"><![CDATA[<p>Last Friday, <a href="http://www.brandonw.net/">Brandon Wilson</a> and I gave a talk on BadUSB at DerbyCon - I wrote some <a href="https://adamcaudill.com/2014/10/02/making-badusb-work-for-you-derbycon/">about it yesterday</a>. Yesterday, Wired <a href="http://www.wired.com/2014/10/code-published-for-unfixable-usb-attack/">published</a> an article on the talk, kicking off several others - only the authors of the Wired and <a href="http://threatpost.com/badusb-attack-code-publicly-disclosed">Threatpost</a> articles contacted us for input.</p>

<p>There has been some questions raised as to the responsibility of releasing the code - so I want to take a few minutes to talk about what we released, why, and what the risks actually are.</p>

<h2>What we released.</h2>

<p>We released a two patches to the existing (v1.03.53) firmware for the Phison 2251-03, and a minimal custom firmware for that same chip.</p>

<p><strong>The Patches</strong></p>

<p>First, let me briefly describe the patches:</p>

<ul>
<li>Hidden Partition - A patch to create a second hidden partition, to show that data can be hidden, and not easily accessed unless you know the trick.</li>
<li>Password Bypass - A patch to modify the password protection mechanism to force the password to fixed value; so that any password will be accepted. Must be applied before the password is set by the user.</li>
</ul>


<p>The second patch does defeat a “security” mechanism on the device, though given that the patch must be applied before the password is set - it’s not a huge risk to users. We intentionally focused on changing behavior instead of adding composite devices, to show that the is more complex than what was displayed at the Black Hat talk.</p>

<p>So we’ve bypassed one security feature, and added a new feature.</p>

<p>The patches were carefully selected to make the point, while not endangering users.</p>

<p><strong>The Custom Firmware</strong></p>

<p>The custom firmware acts a HID device, typing out a pre-programmed payload when inserted to a computer. This is anything but new - this can be done with a <a href="https://hakshop.myshopify.com/products/usb-rubber-ducky-deluxe">USB Rubber Ducky</a>, a <a href="https://www.pjrc.com/teensy/">Teensy</a>, or a number of other devices.</p>

<p>This was released to prove the point that the device could be reprogrammed to be something completely different. If this is a new threat to anyone - they are very out of the loop.</p>

<p><strong>The Tools</strong></p>

<p>We also released a few tools that we developed to apply patches and to make our lives easier during the effort. Most of what they do is available in other tools from Phison or the device manufactures; we built the tools we needed, so we didn’t have to use third-party tools or deal with the limitations of those tools.</p>

<h2>What we DIDN’T release</h2>

<p>Now that we’ve talked about what was released, let’s talk about what it isn’t.</p>

<p><strong>Self replication</strong> - There’s no self replication code anywhere, while it’s possible that it could be done, and we’ve talked about how to do it - it won’t be released.</p>

<p>I am confident that we (Brandon and I) could build a system that would infect PCs, then infect a significant percentage of thumb drives, and then infect other PCs - but, and this is a <em>big</em> but - what we released doesn’t make that easier in any significant way.</p>

<p>Your average script kiddy will never be able to do it; there’s only a small number of people that would be able to do the work needed to be able to pull it off - those people could already do it before we released what we did.</p>

<p>The threat of this happening is the same as it has always been.</p>

<p><strong>Malware</strong> - There’s nothing malicious about what we’ve released here. While we did release a patch to modify the password protection feature - that’s all it does. It doesn’t modify data, infect computers with anything, or anything of that nature.</p>

<p>It changes the way a feature works. That’s it. This is a change that anyone with the required skills could have made - by making it public, we are raising awareness that users shouldn’t blindly trust.</p>

<p><strong>The end of USB as we know it</strong> - Nothing, nothing, that we’ve released has suddenly made new attacks possible. The USB specification allows composite devices to do unexpected things. USB devices (thumb drives or otherwise) that allow anyone to update the firmware without any checks, means that anything can potentially be reprogrammed to change functionality or become malicious.</p>

<p>All of these things have been true long before we released the first line of code. Anyone that believes otherwise doesn’t understand the technology.</p>

<p><strong>An unfixable issue that will end the world</strong> - While there isn’t quick fix for this, things can be improved quite a bit. We released simple code, that proves the issue, draws attention to the fact that users need to be more careful, while being careful to not cause more harm than good in the process.</p>

<p>This isn’t earth shattering. Anyone that thinks that it is, should probably give up and go live in a cave.</p>

<h2>The Risks</h2>

<p>What are the real risks here - what does this expose users to that it didn’t in the past?</p>

<p>Writing code for these devices is far from easy, especially when trying to patch the existing firmware. It’s not something that just anyone can jump into - while we have made it easier for people to apply simple patches and provided some insight to the process, these aren’t the patches that will lead to a firmware based worm or something of that nature - these are the type of patches that will make small changes to existing features, or add simple new features. Even then, it’s time consuming and difficult work.</p>

<p>So, to do anything still requires a lot of knowledge and skill - in general, as I said earlier, the kind of people that have what it takes to do this, could do it regardless of our release.</p>

<p>If a person (or group) was so inclined to take one of these devices and make it truly malicious - it’s unlikely that our research would have an impact.</p>

<p>I firmly believe that by releasing this code, the risk to the average user isn’t increased at all over what it already was.</p>

<h2>Why release?</h2>

<p>Device manufactures were quick to dismiss the “BadUSB” threat - on one hand, what was presented at Black Hat was possible via other means, so wasn’t really a new threat - but they showed no indication of trying to address the issues under their control.</p>

<p>For years devices have been sold with updatable firmware, but with no security checks at all - we had two goals with the release of the code:</p>

<ul>
<li>User awareness - As long as users implicitly trust devices, attacks will be possible and successful.</li>
<li>Push device manufactures to implement signed updates.</li>
</ul>


<p>While it will take years for any changes made by device manufactures to have an impact because of the number of devices in circulation now - if they keep ignoring the issue, then it will never be improved.</p>

<p>In doing this, we haven’t broken the security of these devices, but made it clear that it isn’t existent. If anyone is upset that we’ve removed the obscurity that had “protected” these devices - then to them I’m sorry that they understand so little that they believe that it’s real protection.</p>

<p>Part of the reason we released the “hidden partition” patch was to show that this can be used to add new features, that can add value in certain cases.</p>

<h2>The Full Disclosure debate</h2>

<p>When we started on this, we were concerned that this was being touted as a new threat, yet for defenders there was no way they could even test it, much less develop defense techniques.</p>

<p>So not only do we have something that defenders can’t test, we have something that the device manufactures are downplaying or ignoring. This is the setup for the classic full disclosure debate.</p>

<p>The first question that we asked ourselves, before we wrote the first line of code, is what is best for users? To allow the status quo to continue, or to expand the research into new directions and publish - to help make users aware and provide defenders something to work with.</p>

<p>The answer we came up with, is that we could develop patches that would clearly communicate the issue, without causing undue harm to end users.</p>

<p>In the end, looking at what we intended to release, what could be done that wouldn’t have been possible before that (which is fairly minimal), and the potential benefit - we felt, and still do, that full disclosure was appropriate.</p>

<p>In everything we’ve done, the priority has been protecting users - any media report that indicates otherwise is ill-informed, and providing bad information to the public.</p>

<h2>Breaking out of the echo chamber</h2>

<p>Given that the issue was so well known, the amount of attention - positive and negative - that this has received has really surprised us. It’s too common that when something like this is released it stays within the infosec echo chamber - this has broken out far more than I expected.</p>

<p>Most of the negative feedback has been from people and organizations that are well outside of the echo chamber - reminding me of just how ignorant the public can be when it comes to technical issues.</p>

<p>There are times that I wonder why we work so hard to protect these people.</p>

<h2>Has this been blown out of proportion?</h2>

<p>Yes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making BadUSB Work For You - DerbyCon]]></title>
    <link href="https://adamcaudill.com//2014/10/02/making-badusb-work-for-you-derbycon/"/>
    <updated>2014-10-02T22:15:00-04:00</updated>
    <id>https://adamcaudill.com//2014/10/02/making-badusb-work-for-you-derbycon</id>
    <content type="html"><![CDATA[<p>Last week <a href="http://www.brandonw.net/">Brandon Wilson</a> and I were honored to speak at <a href="https://www.derbycon.com/">DerbyCon</a>, on the work we’ve been doing on the Phison controller found in many USB thumb drives. This was my first time speaking at DerbyCon - it’s a great event, with a fantastic team making the magic happen.</p>

<p>Slides:</p>

<iframe src="https://adamcaudill.com///www.slideshare.net/slideshow/embed_code/39583508" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p>Video (which I’ve haven’t been able to bring myself to watch):</p>

<iframe width="854" height="510" src="https://adamcaudill.com///www.youtube.com/embed/xcsxeJz3blI" frameborder="0" allowfullscreen></iframe>


<p>Now that the dust has settled, I would like to provide some updates, thoughts, and extra information - and <em>maybe</em> correct an error I made during the presentation.</p>

<h3>The Demos</h3>

<p>We did three demos - they were simple enough that I didn’t think there was any risk of having issues. Well, lesson learned.</p>

<p>The machine we used was a fresh Windows install just for the talk - though in the rush, there were a couple differences between it and the machine we had been testing with. In the panic of trying to get the talk done in the short 25-minute slot, I mistook these differences for a failing of one of the demos.</p>

<p><strong>Custom HID Firmware</strong></p>

<p>The first of the three demos was a completely custom firmware, that presents itself as a HID device (and as a mass storage device, though without media present - this is to make firmware updates easier) - the demo went without a hitch.</p>

<p>I would have liked to show the tools and the update process, though there just wasn’t time. Brandon is working on videos that will be posted to YouTube that walks through each demo step by step.</p>

<p>The team behind the <a href="https://hakshop.myshopify.com/products/usb-rubber-ducky-deluxe">Rubber Ducky</a> saved us a lot of time, thanks to the tools they had built - as we were able to support the same encoded format they used.</p>

<p><strong>Hidden Partition</strong></p>

<p>The hidden partition is a great patch, as there’s no way to tell that it’s there - everything works as expected, no reason to suspect that anything has been altered.</p>

<p>It divides the NAND space into two partitions, and the firmware lies about the size, to indicate that only half of the space is there. The “public” section is the first that’s mounted, and only a specific action will cause the second, hidden partition to become visible.</p>

<p>It’s a simple change, but it sends a clear message that there can be more than meets the eye with these devices. From a forensics perspective, the only way to ensure that what you are getting is accurate and complete, is to dump the NAND directly - without allowing the controller to access it.</p>

<p><strong>Password Protection Bypass</strong></p>

<p>This demo <em>seemed</em> to go wrong, but it actually performed perfectly - I was just in too much of a rush to think though what was happening, and why I didn’t see what I expected.</p>

<p>When I plugged the device in, I was expecting to see two drives from it - one “public”, the other unmounted. I only saw one. Two things went wrong here:</p>

<ul>
<li>“Show Empty Drives In Explorer” - By default Windows doesn’t show unmounted removable drives in “My Computer”; this is a setting I always change, and expected to see the unmounted drive. As this was a fresh install, the default setting was still set - the drive was there, I just couldn’t see it. This threw me off.</li>
<li>Wrong Password - During the demo I typed in some random junk to the password field of the “Lock” tool, and instead of it unlocking the drive as expected, it gave me the wrong password dialog. The issue here is a bug in the Phison code, when supplying a password more than 16 characters long it treats it as a bad password. So it was working, but the password I supplied was too long, triggering that bug.</li>
</ul>


<p>We later tested that drive again, and sure enough - it worked flawlessly, as long as the random password wasn’t longer than 16 characters.</p>

<p>The patch works by altering the buffer that stores the data once received over USB; it forces it to 16 “A”s, so that any password will work. Because of how it works, the patch must be applied before the user sets their password - otherwise it’ll just make the data inaccessible.</p>

<p>That was painful.</p>

<h3>The (maybe) error…</h3>

<p>During the talk I referred to modes 7 and 8 as being encrypted - this is <em>probably</em> wrong, at least on the devices we demoed. The two modes are password protected, and according to some documentation are encrypted, and according to other documentation they aren’t.</p>

<p>The question came up in a conversation after the talk - we’ve not had the time to dig into this feature more since then, but it’s looking like it’s just a password check with no encryption.</p>

<p>The password changing patch was added at the last minute, to replace another demo that we didn’t like - we identified the USB command being sent, and patched it. Due to time constraints we didn’t dig into the feature to verify the document (from a device manufacturer) was correct; after the question was raised we dug into a little more and looked for other documentation and code to support the claim - it looks like the document we were referencing was incorrect.</p>

<p>So, it looks like I misspoke - the patch still works as expected, though the feature itself seems to provide less protection than we initially though. Sorry!</p>

<h3>The Code &amp; Docs</h3>

<p>We have everything on the <a href="https://github.com/adamcaudill/Psychson">repo</a> now, and we’ve added some additional documentation to the <a href="https://github.com/adamcaudill/Psychson/wiki">wiki</a>.</p>

<p>This isn’t simple to do - the code is complicated to write, and the effort to use the patches and custom firmware is a bit more than I’d like. We’ve tried to document things as well as we can, hopefully it’s easy enough to understand.</p>

<h3>Next Steps</h3>

<p>We really hope that releasing this will push device manufactures to insist on signed firmware updates, and that Phison will add support for signed updates to all of the controllers it sells.</p>

<p>Phison isn’t the only player here, though they are the most common - I’d love to see them take the lead in improving security for these devices. They have an opportunity to stand up and protect users - as the most common provider of these controllers, I’d truly love to see them take this as an opportunity to lead the industry.</p>

<p>What we’ve released just scratches the surface of what can be done here - until signed updates are enforced, there’s no telling what games these devices could be playing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IETF Action on Secure Email]]></title>
    <link href="https://adamcaudill.com//2014/08/25/ietf-action-on-secure-email/"/>
    <updated>2014-08-25T11:02:00-04:00</updated>
    <id>https://adamcaudill.com//2014/08/25/ietf-action-on-secure-email</id>
    <content type="html"><![CDATA[<p>Early last week I emailed a group of IETF Area Directors, for the Security and Applications areas, asking them to start the process of creating a new Working Group to address the issues around email security. (Thanks Adrian Farrel for the prodding!)</p>

<p>Today, the first result of the effort has been completed - the new <a href="https://www.ietf.org/mailman/listinfo/endymail">endymail</a> mailing list. An IETF venue to discuss how these issues can be addressed, hopefully laying the ground work updated standards to improve email as we know it today, and eventually standardizing a replacement to SMTP and related protocols. Here&#8217;s the description that the group came up with for the new list:</p>

<blockquote><p>There is significant interest in improving the<br/>privacy-related properties of Internet mail. One focus of<br/>current efforts is on the per-hop (connection-based)<br/>protections provided by TLS. However a wide range of other<br/>work has a focus on end-to-end protection, at the Internet<br/>scale of billions of end users and perhaps millions of<br/>operators.  Such work typically involves new forms of mail<br/>header or body protection, new public key management<br/>(compared to S/MIME or PGP), and security mechanisms more<br/>appropriate for mobile/web user-agents.  Other<br/>security-relevant approaches may be discussed if needed.<br/>Various proposals and development efforts on this topic are<br/>underway outside the IETF. This mailing list provides an<br/>IETF venue for discussion of elements that might be commonly<br/>needed by such efforts and to identify work that the IETF<br/>could do to aid in achieving better end-to-end security<br/>deployed for Internet email.</p></blockquote>


<p>While the creation of another mailing list is far from ground breaking, it&#8217;s the necessary first step in standardizing a solution to a decades old problem.</p>

<p>I encourage everyone interested in email security and privacy to join the list, and participate in the discussions that will lead to new standards. (Though please wait a bit for people to subscribe before starting discussions.)</p>

<p>A big thanks to Stephen Farrell, Joe Hildebrand, and Pete Resnick for their enthusiastic support for this effort.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SMIMP at the DEFCON Crypto Village]]></title>
    <link href="https://adamcaudill.com//2014/08/16/smimp-at-the-defcon-cryptovillage/"/>
    <updated>2014-08-16T00:00:00-04:00</updated>
    <id>https://adamcaudill.com//2014/08/16/smimp-at-the-defcon-cryptovillage</id>
    <content type="html"><![CDATA[<p>Last week I gave a lighting talk at the DEFCON CryptoVillage on <a href="http://smimp.org/">SMIMP</a>. The talk went over the basics of why the project is needed, and how the specification works.</p>

<p>Here are the slides:</p>

<iframe src="https://adamcaudill.com///www.slideshare.net/slideshow/embed_code/38040741?rel=0&startSlide=2" width="512" height="421" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p>Here is a rough transcript of the talk:</p>

<p><em>Slide 1:</em> I&#8217;m Adam Caudill, I’m a developer and security researcher; I work on a number of different things, but my recent work has been around privacy and secure messaging.</p>

<p>We all know that email security is a real problem, and thanks to a certain whistleblower we know those weaknesses are actively being exploited on a massive scale. I&#8217;m here to talk about some of the issues, and a project I&#8217;ve been working on called SMIMP. It&#8217;s a secure messaging protocol that aims to address the use cases of email, and to be a viable option to replace email as we know it.</p>

<p><em>Slide 2:</em> This image illustrates the issues with email better than anything I&#8217;ve seen.</p>

<p>It&#8217;s decades old, wasn&#8217;t designed for the threats that exist today, and as a result - this is what we&#8217;ve done to it. We&#8217;ve glued on various bits to make it look and feel like something it isn&#8217;t. STARTTLS helps protect from passive monitoring, but that&#8217;s only one attack vector out of so many - and even then, it&#8217;s often opportunistic, so it fails open and is subject to Man In The Middle attacks.</p>

<p>GPG helps protect message content, but it&#8217;s hard for the average user to understand and doesn&#8217;t do anything for metadata.</p>

<p>No matter what we try to glue on to email, it&#8217;s still a protocol that fails on many fronts.</p>

<p><em>Slide 3:</em> Not only is email as it exists today not designed to provide any protection from state-level attackers, it doesn&#8217;t even provide any protection from a rogue sysadmin. Thanks to the various bits that have been glued on over the years, it&#8217;s a bit better when circumstances are ideal - but it still fails on so many fronts.</p>

<p>For a messaging protocol to have any chance of being secure, privacy and security need to be evaluated and included in every design decision, from the very first day - attempting to glue them on after the fact leads to the kind of failure we&#8217;ve seen with email.</p>

<p>I know I&#8217;m preaching to the choir here. We all know it&#8217;s a mess, we all know it&#8217;s a problem that needs to be addressed.</p>

<p><em>Slide 4:</em> There are many people looking to make the situation better, and on many fronts, and these efforts  do help a little bit at a time - but often only for people that know how to leverage the tools, or can get others to implement solutions. For the vast majority of users, the current state of email security is pretty dismal.</p>

<p>The question is, does it make sense, in the long term, to keep trying to find ways to improve email with security focused clients (such as Mailpile), better self-hosting setups, fighting companies to implement STARTTLS, and so on. Or, should we be pushing for a new protocol that&#8217;s built for security and privacy from the ground up? Avoiding the mistakes of the past, shedding the dead weight of obsolete protocols and techniques.</p>

<p>There are huge compatibility and interoperability issues that have to be addressed for any protocol to be successful of course - when you are trying to replace a system used by billions, dealing with legacy systems is something of a big deal.</p>

<p>The fact is, it <em>needs</em> to be replaced with something better, but even calling such an effort a massive undertaking is an understatement. But, if it is to be replaced, it needs to start with groups like this, so that what&#8217;s built will live up to the demands that will be placed on it.</p>

<p><em>Slide 5:</em> Towards the goal of finding a better option for email, I began writing a specification. If I&#8217;m going to complain about a problem I should offer a solution, right?</p>

<p>SMIMP is a general purpose messaging system designed with a few key goals in mind:</p>

<ul>
<li>Minimal metadata</li>
<li>Encrypt as much as possible</li>
<li>Covers existing email use cases</li>
<li>Simple to use; normal users need to be able to use it</li>
<li>Useable in corporate environments that have special handling requirements - such as HIPAA, SarbOx, etc. - This is a big advantage against options like bitmessage; there has to be a balance between security, and meeting the varying demands of the different environments this could be used in.</li>
</ul>


<p>Another goal is ease of implementation - on both the client and server ends; so it&#8217;s a REST-like web service, and the data is passed as JSON. This way developers can leverage well-tested code instead of writing everything from scratch. This also means that it&#8217;s easy for people to host their own server with a minimal time / effort investment.</p>

<p><em>Slide 6:</em> SMIMP is made up of two major components, identity management and messaging. I believe it&#8217;s critical that these are combined into a single protocol to allow for key pain points in traditional email to be addressed - the largest being public key discovery. For GPG, this can be a real challenge for users, especially when trying to find the key for certain high-profile people; has anyone looked for Jacob Applebaum&#8217;s key? It&#8217;s Bad.</p>

<p>Every user has one public signing key in their profile information - the key is tied to the user&#8217;s address, so to find a user&#8217;s key, all you need is their address. This provides a clean, simple way to identify the appropriate key for a user. Of course, ideally users should verify public signing keys via a trusted channel such as a phone call.</p>

<p>To protect the integrity of the profile information, all changes are signed with the user&#8217;s signing key, and includes the hash of the prior change - creating a hash chain from the first, to the most recent change, allowing for simple validation that the records haven&#8217;t been altered.</p>

<p>To protect against a malicious server, there are a couple checks that clients can perform:</p>

<ul>
<li>Pin the most recent signing key, if it disappears from the user&#8217;s profile, then the information is being truncated, possibly to force the use of a compromised key.</li>
<li>Pin the original signing key from when the account was created; if that ever changes, that is a clear indication that the entire history for a user has been replaced.</li>
</ul>


<p>On the messaging side, all messages and most metadata is encrypted; the only data exposed is the data needed for the server to function. There are multiple message types, so not only does it support email like messages, it supports custom, application specific messages; this allows other message-centric applications to use SMIMP as a transport, making it easier to build secure messaging applications.</p>

<p>There are a few anti-spam protections in place - seeing as the server won&#8217;t be able to scan content anymore.</p>

<ul>
<li>Dynamic hashcash-like proof of work</li>
<li>Blacklists to reject everything from an address or domain</li>
<li>Whitelists to allow addresses or domains to bypass the proof of work check.</li>
</ul>


<p>The envelope is JSON, for email, the message is JSON, the formats are extensible, making it easy to add new functionality.</p>

<p>Everything is designed around a simple set of principles:</p>

<ul>
<li>Secure</li>
<li>Private</li>
<li>Easy to implement</li>
<li>Hard to screw-up</li>
</ul>


<p><em>Slide 7:</em> So, what&#8217;s the status today&#8230;</p>

<p>The specification is still a work in progress and is available from smimp.org, along with more background of what it is, and why it&#8217;s designed the way it is.</p>

<p>I wouldn&#8217;t try building against it just yet, it&#8217;s still too immature, but if anybody wants to put their 2 cents in, the specification is on github and pull requests are welcome. The goal here is to get feedback, address issues, and try to build a community driven specification - my goal isn&#8217;t to write a specification myself and then push it on the world assuming it&#8217;s perfect.</p>

<p>I&#8217;ve invested a fair bit of time into SMIMP, but it&#8217;s certainly not perfect, and the final solution to the email problem may not be anything like SMIMP - and I&#8217;m fine with that.</p>

<p>What&#8217;s needed is more people looking not at how to we glue more things on email, but looking at how could we replace it. We need to get more people talking about possible solutions, for more people to contribute to specifications, or write new ones, to get more people focused on the one goal that will actually fix email security - replacing it.</p>

<p><em>Slide 8:</em> I encourage you to look at the specification, to think about how replacing email could be achieved, and find people to work with to achieve this.</p>

<p>If you have any questions, suggestions, or complaints - I&#8217;ll be in the area for a bit.</p>

<p>Thanks!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Strong Identity Management]]></title>
    <link href="https://adamcaudill.com//2014/07/26/on-strong-identity-management/"/>
    <updated>2014-07-26T22:16:00-04:00</updated>
    <id>https://adamcaudill.com//2014/07/26/on-strong-identity-management</id>
    <content type="html"><![CDATA[<p>Alice wants to send an encrypted message to Bob; she knows his address, but doesn&#8217;t know the public key that goes with that address. Using GPG, Alice would look up his address on a key server, the issue is of course that anyone can upload a key associated with Bob&#8217;s address.</p>

<p>Using the &#8220;web of trust&#8221; model, Alice would look at the different keys and see which ones are signed, and if any of them are signed by people she knows. The problem is that Alice doesn&#8217;t normally use GPG, and she hasn&#8217;t marked the keys of the people she knows as trusted (I expect this is true for most casual GPG users), thus, she can&#8217;t tell what key is signed by keys she should trust, versus the ones signed by keys she shouldn&#8217;t.</p>

<p>In years of effort, this is still an issue.</p>

<p>There are many issues with this model, especially when it comes to casual users that don&#8217;t understand the details of the &#8220;web of trust&#8221; - while GPG use is certainly going up thanks largely to the Snowden revelations, many of these users fit into the casual users group. Thanks to the complexities of the model, these users may not be getting the level of protection they think they are.</p>

<p>Here are just a few of these issues:</p>

<ul>
<li>Lack of strong linking - there isn&#8217;t a strong, verifiable connection between a user&#8217;s address, and their public key.</li>
<li>Complex user interaction - to be useful, the user has to understand the web of trust model, and how to leverage it. Based on the discussions I&#8217;ve had with people that recently started using it, most don&#8217;t get it.</li>
<li>Key discovery - finding the right key can be a nightmare, especially for some people. When there are multiple &#8220;valid&#8221; keys published, each with signatures, it can be hard for novice users to figure out which one is right.</li>
</ul>


<p>I could go on, but I think the point is clear - the web of trust works well for some users, but only the users that take the time to really understand it.</p>

<p><strong>The <em>IM</em> in SMIMP</strong></p>

<p>I&#8217;ve been drafting a <a href="https://github.com/smimp/smimp_spec">specification</a> for a secure messaging protocol called <a href="http://smimp.org/">SMIMP</a>, as far as I&#8217;m concerned the Identity Management component is the most important part. It&#8217;s what allows the rest to work - secure messaging isn&#8217;t that hard, key handling and validation is where end user system start to fail.</p>

<p>To provide a strong identity management system, a few goals need to be met:</p>

<ul>
<li>Strong link between address and public key.</li>
<li>Updates to identity information signed by the user to prevent unauthorized changes.</li>
<li>Provide a full history, including all changes from the time the account was created.</li>
<li>Use of a hash-chain to show that no changes have been removed.</li>
</ul>


<p>The IM in SMIMP meets all of these. The suggested way of using the system is trust on first use, pinning on both the first and the most recent public key. It would also be wise for the user to validate the recipient&#8217;s current public key via a trusted channel on first use, but that&#8217;s something that rarely happens in practice.</p>

<p>To detect a malicious server, or modified traffic, the user&#8217;s client should first check to see if the original public key has changed - if it has, it indicates that the user&#8217;s information has been replaced in its entirety. Second, it should see if the most recent key is no longer listed in the user&#8217;s history - if its been removed, it indicates that the user&#8217;s history has been truncated, possibly in an attempt to encourage the use of a compromised key. These checks provide an easy way for client software to validate that keys can be trusted.</p>

<p>To make the system more useful, the SMIMP identity information includes more than just the public key (all of which are optional):</p>

<ul>
<li>Name</li>
<li>Web site</li>
<li>List of social media profiles</li>
<li>Additional data (comments, or other data the user wishes to assert)</li>
</ul>


<p>This provides a simple way to strongly tie addresses to public keys; thus making secure messaging easier and more understandable for casual / non-technical users. For a solution to be widely useable, it needs to be effective for everyone.</p>

<p><strong>The best solution?</strong></p>

<p>SMIMP may not be the best solution, and there are some things about it that I don&#8217;t care for myself - such as exposure of more metadata than I&#8217;d like. But, it is a solution to the issues surrounding email, and identity management.</p>

<p>The <a href="https://adamcaudill.com/2014/06/27/the-sinking-ship-of-email-security/">issues</a> of email security can be fixed, and identity management is part of that problem. There has to be a way to tie a user to their public key in a more reliable manor than what we have today (and without resorting to the mandatory government ID idea that won&#8217;t die).</p>

<p>I encourage everyone to look at these issues, and think about possible solutions. Contribute to SMIMP or one of the other efforts to fix the issues around email; we can no longer ignore these issues. The community needs to find and implement solutions that assure the security and privacy of the global community.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jumping through hoops...]]></title>
    <link href="https://adamcaudill.com//2014/07/23/jumping-through-hoops-dot-dot-dot/"/>
    <updated>2014-07-23T18:11:00-04:00</updated>
    <id>https://adamcaudill.com//2014/07/23/jumping-through-hoops-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>There are two ways to implement security:</p>

<ul>
<li>Real security, based on empirical evidense and analysis.</li>
<li>Checklist security, based on the latest checklist somebody says is important.</li>
</ul>


<p>When security is based on real evidence and analysis, policies are enacted based on real gain and measured against the business impact. Risks are considered, and the costs versus benefits are well understood so that policy choices are based on real, useful information.</p>

<p>On the other hand there&#8217;s security by checklist. Costs aren&#8217;t calculated, risks aren&#8217;t understood, business impacts are ignored. All that matters is that somebody gets to check a box on a form; there&#8217;s no understanding, no logic, and likely no real benefits involved.</p>

<p>The point of security policies isn&#8217;t to show off how many hoops you&#8217;ve built that people have to jump through when doing their jobs. Yet, when a company accepts a security by checklist mentality, this is exactly what they are doing. They spend their time building hoops that they can show off later while ignoring the threats they are supposed to be addressing.</p>

<p>Recently, my laptop died, the new laptop was setup with DLP, or digital loss prevention software. The main purpose of the software is to prevent me and anyone in my group from being able to use removable drives - so that we can&#8217;t load them up with private information of course.</p>

<p>This was done to check a box on a form, at no point did anyone actually think about the bigger picture, what the threat was, and how it should be addressed:</p>

<ul>
<li>I have a laptop and work remotely.</li>
<li>When I disconnect from the VPN, I have unrestricted access to the internet.</li>
<li>I routinely work with sensitive data, so it&#8217;s not uncommon for it to be on my computer.</li>
<li>I could easily encrypt a file full of private data, and upload it to the cloud after disconnecting from the VPN, and nobody would know.</li>
</ul>


<p>So, by blocking the use of removable drives, they made it much harder for me to recover from a failing laptop, and added nothing to security. Blocking thumb drives won&#8217;t stop a person from stealing data when they have other ways they could do the same thing. All it did was waste time and the company&#8217;s money.</p>

<p>They built a new hoop to show off, nothing more.</p>

<p>Such policies don&#8217;t help anyone - they don&#8217;t improve security, they certainly don&#8217;t prevent theft of data, and at the same time, they do have a negative business impact. Lost productivity, increased frustration, and in the end higher turn-over from employees that are fed up from the meaningless work. There&#8217;s no winner here - except the person that wants to show off all of the hoops they have.</p>

<p>Security based on anything other than empirical evidence and legitimate analysis is just theater and nothing more.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Sinking Ship of E-Mail Security]]></title>
    <link href="https://adamcaudill.com//2014/06/27/the-sinking-ship-of-email-security/"/>
    <updated>2014-06-27T23:32:00-04:00</updated>
    <id>https://adamcaudill.com//2014/06/27/the-sinking-ship-of-email-security</id>
    <content type="html"><![CDATA[<p>E-Mail, the venerable old standard for internet text messages, dating back to the early 1980s - and back to the early 1970s in other forms, has long been the &#8220;killer app&#8221; of the internet. While so many companies try to make the next great thing that&#8217;ll capture users around the world - none of these compare to the success of e-mail. It is likely the single most entrenched application-layer protocol used today.</p>

<p>Thanks to <a href="https://en.wikipedia.org/wiki/Stellar_Wind">STELLARWIND</a> and other NSA programs, we have also seen that it has failed in a very real, and very important way.</p>

<p>But this isn&#8217;t exactly news is it?</p>

<p>The security issues around e-mail - or rather the complete lack of security in the protocol has been well understood for decades. Yet, in all those years of existence, all we, as those that care about security have managed to do is glue ineffective solutions on it.</p>

<p><strong>STARTTLS</strong></p>

<p>In the last year, since the scope of NSA&#8217;s spying has been made clear to the world - and the reminder that the NSA isn&#8217;t the only player in this game, the use of STARTTLS has <a href="https://www.google.com/transparencyreport/saferemail/?hl=en">spread dramatically</a>. Many people have worked hard to make this happen - and it really has made things better. Kinda.</p>

<p>While STARTTLS does enable TLS, thus encrypting the data over the wire, it&#8217;s far from perfect:</p>

<ul>
<li>Opportunistic - In the majority of occasions the encryption is opportunistic; meaning that certificates aren&#8217;t validated, and if something goes wrong in the TLS negotiation, the connection will fail-open - passing data in the clear.</li>
<li>Server Trust - E-mail as it exists today places complete trust in not only the sending server, but also the recipients server - and every other relaying server. Any of these can log all correspondence, as the data is only encrypted during the transport. TLS can be added or dropped at any point in the chain, and this exposes multiple possible intercept points.</li>
</ul>


<p>Based on the famous &#8220;SSL added and removed here&#8221; NSA slide, we see that even if the messages are sent over an encrypted connection, that doesn&#8217;t mean they stay encrypted when moved around within a company. There are so many failure points that can lead to an attacker being able to collect data.</p>

<p>So if groups like the NSA want e-mail, it takes some extra effort thanks to STARTTLS, but it doesn&#8217;t solve the problem.</p>

<p><strong>PGP / GPG</strong></p>

<p>PGP, and the compatible (and likely more commonly used) GPG are one of the best options people have to encrypt their email - but there&#8217;s still a great deal of data exposed.</p>

<ul>
<li>UX - The user experience for most applications goes beyond unfriendly, to the point of being actively hostile. I recently walked an experienced developer through setting up a key with Gpg4win - the process of getting everything setup and working was beyond painful. The only GPG wrapper that I&#8217;ve seen that isn&#8217;t unreasonably difficult is GPGTools for OSX.</li>
<li>Web of Trust - The web of trust model that PGP uses is both genius and terrible. When a news organization started using PGP, I noticed that none of their keys were signed by anyone - so I tried explaining the concept to one of their journalists. After several tweets we moved the conversation to e-mail, which led to several multi-page emails. By the end, I think he was more confused than ever. Last I checked, their keys still aren&#8217;t signed.</li>
<li>Metadata - <a href="http://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata/">Metadata kills</a>. It&#8217;s scary but true - people die based on who they talk to. How long till an investigative journalist reporting on an organization not friendly to the US gets droned for emailing the wrong people? PGP doesn&#8217;t hide who is emailed, the subject, or any of the headers. PGP encrypted email leaks useful information like a sieve.</li>
<li>Client Integration - Not many email clients natively support PGP, so most users have to encrypt manually, or use a third-party add-on. This can lead to interesting information leaks, such as saving unencrypted drafts to the server.</li>
<li>Mobile - Using PGP on a mobile device can be risky, as it requires storing the private key on devices that are likely to have known security issues. Many people recommend against it, as it puts the private key at too much risk.</li>
</ul>


<p>So while PGP / GPG protects the content of email, it still is subject to metadata collection.</p>

<p><strong>S/MIME</strong></p>

<p>For those that don&#8217;t like PGP, or want a better chance of having native support, there&#8217;s S/MIME. Like PGP, S/MIME has it&#8217;s share of issues which leave users with less protection than they realize.</p>

<ul>
<li>Certificates - To use S/MIME, you have to have a certificate issued from a CA. The question is, how trustworthy is it? CAs have been hacked to issue bad certificates in the past, and nobody knows what an NSL could be used for when issued to a CA.</li>
<li>Key Escrow - Some CAs generate the private key on their side to allow them to provide a key escrow service. While this can be useful if you ever lose your key and want to read your email again, it also runs the risk of an unauthorized party getting access to the key.</li>
<li>Metadata - The metadata issues noted for PGP applies here as well. The subject, the recipients, the headers are all in clear text.</li>
</ul>


<p>There are other various complaints around S/MIME that are well documented, and have been discussed countless times. The point is, it&#8217;s another partial solution just glued onto email in an attempt to make it do something it was never designed to do. Be secure.</p>

<p><strong>The list goes on&#8230;</strong></p>

<p>Much work has went into other various add-ons, such as SPF and DKIM and others that attempt to do things that could have been done by default if e-mail had been designed with authentication, privacy, and security in mind.</p>

<p>When e-mail was designed, none of these issues were considered - people have been trying to find ways to fix that mistake for years. E-mail was open, plain text, security and privacy weren&#8217;t considered - or at least not to the extent required.</p>

<p>For a system like e-mail to be secure, security has to be part of the core design, considered at every step. When security &amp; privacy are an afterthought, something to just glue on - it&#8217;s impossible to achieve either.</p>

<p>There are many efforts underway now to improve the situation, some such as <a href="https://www.mailpile.is/">Mailpile</a>, I greatly respect. Their goals are noble, their purpose is true - but I also think they are fighting the wrong battle. E-mail as we know it is flawed beyond repair - we can make it leak less, but for all the work trying to overcome the design flaws, it&#8217;ll always be flawed. There&#8217;s only one way for e-mail to ever be secure.</p>

<p><strong>Time for action!</strong></p>

<p>Over the past few months I&#8217;ve been working on a specification for a system to replace e-mail. I don&#8217;t know if it&#8217;ll ever go anywhere - but that&#8217;s not the point. E-mail as we know it needs to be replaced - it can&#8217;t be fixed. We need to be discussing how to eliminate email, not new ways to glue partial solutions on to it. STARTTLS isn&#8217;t the answer, PGP isn&#8217;t the answer, S/MIME isn&#8217;t the answer - an entirely new protocol is.</p>

<p>I&#8217;m hoping to make the first public draft available in the next few weeks. If it&#8217;s well received, I&#8217;ll try to do what I can to get the system built. If not, then hopefully others will write competing specifications, and I&#8217;ll aide them as I can.</p>

<p>My goal for the specification I&#8217;m writing is to encourage discussion - to get people talking about how to solve the problem. If it contributes in any way to a new system, a system that&#8217;s designed from the beginning to be secure, then it&#8217;s worth every minute that&#8217;s been invested in it. We need to find a viable option that can replace the monstrosity that we have today.</p>

<p>I encourage everyone to think about solutions to this - how can we build a viable replacement to e-mail that meets the privacy and security goals, while being user friendly, and meeting the requirements of business and government environments. It&#8217;s a hard problem to solve, but it can be solved. It&#8217;s up to us to do it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[phpMyID: Fixing Abandoned OSS Software]]></title>
    <link href="https://adamcaudill.com//2014/04/19/phpmyid-fixing-abandoned-oss-software/"/>
    <updated>2014-04-19T12:43:00-04:00</updated>
    <id>https://adamcaudill.com//2014/04/19/phpmyid-fixing-abandoned-oss-software</id>
    <content type="html"><![CDATA[<p><a href="http://siege.org/phpmyid">phpMyID</a> is a simple solution for those that want to run their own OpenID endpoint - the problem is that its author stopped maintaining the project in 2008. Despite this, there&#8217;s still quite a few people that use it, because it&#8217;s the easiest single-user OpenID option available.</p>

<p>Unfortunately, the author didn&#8217;t follow best practices when building the software, and as a result multiple security flaws were introduced. In 2008, a XSS was identified and never fixed (<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=2008-4730">CVE-2008-4730</a>), in the years since then it seems the software has been below the radar. While conducting a pentest I discovered a previously undocumented XSS (CVE-2014-2890) - which left me with a dilemma - what to do about it?</p>

<p>Looking at the code, I found a couple more potential XSS vulnerabilities - so the application clearly needed help, and if the author won&#8217;t do it, somebody should. Ethically, it seemed wrong to disclose the issue but leave users to fend for themselves; full disclosure is normally used to push a vendor into acting - but in this case it&#8217;s assured that there won&#8217;t be a vendor response.</p>

<p><strong>Fixing The Code</strong></p>

<p>One good thing is if a OSS project is abandoned, anyone can prepare patches to fix the issues. So, <a href="https://github.com/adamcaudill/phpMyID">that&#8217;s what I did</a>. I&#8217;ve committed fixes for both CVE-2008-4730 and CVE-2014-2890, as well as a couple potential issues. In both cases, the fix was easy:</p>

<p>CVE-2008-4730:</p>

<pre><code>@@ -439,7 +439,7 @@ function checkid ( $wait ) {
    if ($trust_root != $return_to) {
        // the urls are not the same, be sure return decends from trust
        if (! url_descends($return_to, $trust_root))
 -          error_500('Invalid trust_root: "' . $trust_root . '"');
 +          error_500('Invalid trust_root: "' . htmlentities($trust_root, ENT_QUOTES) . '"');

    }
</code></pre>

<p>CVE-2014-2890:</p>

<pre><code>@@ -568,7 +568,7 @@ function checkid_setup_mode () {
   */
  function error_mode () {
    isset($_REQUEST['openid_error']) 
 -      ? wrap_html($_REQUEST['openid_error'])
 +      ? wrap_html(htmlentities($_REQUEST['openid_error'], ENT_QUOTES))
        : error_500();
  }
</code></pre>

<p>I&#8217;ve only given the code a quick once-over, so there may be other issues - if I find time for a more thorough review I may commit additional fixes.</p>

<p><strong>Status of phpMyID</strong></p>

<p>I&#8217;m not taking over the maintenance of the project, I simply don&#8217;t have time to do the cleanup needed to bring it up to reasonable standards. I&#8217;d love to see somebody with a little time to invest cleanup the code and add more defensive measures. It needs some help, that&#8217;s clear.</p>

<p>One of the things I&#8217;d love to see fixed is the way the user&#8217;s password is stored - it&#8217;s currently stored in the <code>MyID.config.php</code> file as a MD5 hash - making brute-forcing entirely too easy. Hopefully <a href="http://tools.ietf.org/html/draft-ietf-httpauth-digest-06">this</a> Internet Draft will be adopted soon, obsoleting <a href="http://tools.ietf.org/html/rfc2617">RFC 2617</a>, which will be an easy win to improve the security of the password when in transit. There are many places where the code can be improved by somebody with a little time.</p>

<p>If you are using phpMyID today, replace the <code>MyID.php</code> file with the one <a href="https://raw.githubusercontent.com/adamcaudill/phpMyID/master/MyID.php">here</a> (it also fixes compatibility with PHP 5.4).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Security By Buzzword - Why I don't support Ensafer]]></title>
    <link href="https://adamcaudill.com//2014/03/23/security-by-buzzword-why-i-dont-support-ensafer/"/>
    <updated>2014-03-23T12:28:00-04:00</updated>
    <id>https://adamcaudill.com//2014/03/23/security-by-buzzword-why-i-dont-support-ensafer</id>
    <content type="html"><![CDATA[<p><strong>Update</strong>: I had a call with Ensafer&#8217;s CTO, Trygve Hardersen to discuss the issues I brought up, and what they can do about it. First, they updated the site so that downloads are now over HTTPS. He stated that the infrastructure that powers their service is separate from the website, and everything is over HTTPS. They are working on making documentation available, and hope to have the first documents available soon. Once I get a chance to look over their documentation, I&#8217;ll post further updates.</p>

<p><a href="http://www.ensafer.com/">Ensafer</a> is an overlay to Dropbox that offers end-to-end encryption, the goal being to address privacy concerns that Dropbox can access user&#8217;s files - and thus possibly the US Government (via NSLs, etc.). This sounds like a great idea - end to end encryption is the best way to prevent unjustified surveillance, and I do use a competing product (<a href="https://www.boxcryptor.com/">Boxcryptor</a>), so I support the concept, but what about Ensafer&#8217;s implementation - does it provide the level of security desired?</p>

<p><strong>Where are the details?</strong></p>

<p>If you look at Ensafer&#8217;s site, you&#8217;ll find precious few details on what they are doing - plenty of security buzzwords, but no specifics. Let&#8217;s take a look at the <a href="https://ensafer.zendesk.com/hc/en-us/articles/200797297-Industry-standard-RSA-and-AES-cryptography">one page with details</a>:</p>

<blockquote><p>Ensafer believes in standards and we don&#8217;t use any custom encryption algorithms. Our encryption platform is built on:</p><p>2048-bit RSA keys<br/>256-bit AES encryption<br/>2048-bit SSL<br/>PKCS#12 key containers<br/>X.509 certificates</p></blockquote>


<p>We see some algorithm names - but what about key derivation, or symmetric encryption modes? How about hashing algorithms? How and where is your password stored? There are so many implementation details that are critical for security, yet aren&#8217;t talked about at all.</p>

<p>In December of 2012 I started asking about details, they pointed me back to the web site - when I pushed for more, I was told that they were working on a whitepaper to explain their implementation:</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p><a href="https://twitter.com/adamcaudill">@adamcaudill</a> We have not published all technical details, but we&#39;re working on a whitepaper which will be published later. ^LS</p>&mdash; Ensafer (@Ensafer) <a href="https://twitter.com/Ensafer/statuses/275616564085149698">December 3, 2012</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>More than a year later, I&#8217;m still waiting to see those details.</p>

<p><strong>So have they conducted an audit?</strong></p>

<p>Since they haven&#8217;t released details publicly, if they conducted an external audit, that would bring some trust. So, recently I asked, and this is what they had to say:</p>

<div class='embed tweet'><blockquote class="twitter-tweet" align="center" width="350"><p><a href="https://twitter.com/adamcaudill">@adamcaudill</a> Thanks for your important question. There hasn’t been an audit yet due to work in progress, but will be done this year.</p>&mdash; Ensafer (@Ensafer) <a href="https://twitter.com/Ensafer/statuses/447156694041509889">March 21, 2014</a></blockquote>
<script async src="https://adamcaudill.com///platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>After the delay in getting useful details published, I&#8217;m not hopeful that we&#8217;ll see the results of an audit in the near future.</p>

<p><strong>TLS &amp; Safe Downloads</strong></p>

<p>I really wish that the lack of details was the only concern - but it&#8217;s not. The first thing I noticed is that their web site doesn&#8217;t force TLS, so I manually switched to HTTPS, unfortunately the result wasn&#8217;t what I was hoping for:</p>

<p><img class="center" src="https://adamcaudill.com//files/Ensafer_SSL_Error.png"></p>

<p>Well, that&#8217;s not encouraging. Let&#8217;s take a look at the download link:</p>

<pre><code>http://get.ensafer.com/mac/prod/Ensafer-1.0.8.dmg
</code></pre>

<p>When you try the same link over HTTPS, it&#8217;s even worse:</p>

<p><img class="center" src="https://adamcaudill.com//files/ensafer_dl_no_tls.png"></p>

<p>For a security product, I&#8217;d expect the download to be over HTTPS to prevent an attacker from redirecting a victim to a malicious version. This isn&#8217;t the kind of mistake I&#8217;d expect from people building advanced security tools. When you see issues like this, it&#8217;s common to see more problems, so this may just be the tip of the iceberg.</p>

<p><strong>Is it trustworthy?</strong></p>

<p>I would like to say that it&#8217;s safe to use, and that it lives up to the promises made - but they haven&#8217;t made enough information available for people to make an informed decision. If you add the lack of information with such basic mistakes as not making the download available over HTTPS, it doesn&#8217;t instill much confidence. Companies focused on security should know better.</p>

<p>When you make decisions about what tools you use, you have to look at the full picture - and Ensafer is a great example of that. They&#8217;ve focused first on a pretty website, adding features - but not assuring trust. At this point, the only evidence of their security is the use of buzzwords.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP Considered Harmful - The Need For Negative Feedback]]></title>
    <link href="https://adamcaudill.com//2014/03/15/http-considered-harmful-the-need-for-negative-feedback/"/>
    <updated>2014-03-15T17:53:00-04:00</updated>
    <id>https://adamcaudill.com//2014/03/15/http-considered-harmful-the-need-for-negative-feedback</id>
    <content type="html"><![CDATA[<p>We all know, and well understand what this means when we see it in a browser:</p>

<p><img class="center" src="https://adamcaudill.com//files/GitHub_EV_Cert.png"></p>

<p>It means that the connection is encrypted, and that some degree of validation has occurred to verify that the server is who it claims to be. Through the years, users have been taught to trust sites when they see that, or the all too familiar &#8216;lock&#8217; icon - when users see it, they assume their data is safe.</p>

<p>But what about this?</p>

<p><img class="center" src="https://adamcaudill.com//files/reddit_no_ssl-2.png"></p>

<p>There&#8217;s no lock to tell them they are safe, but there&#8217;s also no warning to indicate that the connection isn&#8217;t secure. There&#8217;s no encryption, no validation, - no protection at all. With HTTP, users are afforded nothing at all to protect them - but we all know that, right? Does the average user understand that though? Do they understand how easily they could be <a href="http://arstechnica.com/tech-policy/2014/02/new-snowden-docs-show-nsa-gchq-spied-on-wikileaks-pirate-bay-users/">monitored</a>, or how easily traffic can be <a href="https://www.schneier.com/blog/archives/2013/10/how_the_nsa_att.html">altered</a>?</p>

<p><strong>The Need For Negative Feedback</strong></p>

<p>Strong negative feedback has long been used in browsers to warn against invalid or expired certificates - but there&#8217;s no feedback to warn users of just how dangerous HTTP can be. After a discussion on Twitter, a friend of mine, <a href="https://twitter.com/defusesec">Taylor Hornby</a>, created a <a href="https://defuse.ca/web-browser-negative-feedback.htm">mockup</a> of what could be done in Firefox to warn users:</p>

<p><img class="center" src="https://adamcaudill.com//files/ff_no_ssl_xmockup-1.png"></p>

<p>This provides simple, clear feedback to the user that they shouldn&#8217;t trust the site - it doesn&#8217;t present an error or anything to interrupt the user, but does make them aware of the risks they are taking.</p>

<p>We, the security community, owe it to users to provide them with useful feedback so that they can protect themselves - providing negative feedback in the browser showing the weakness of HTTP would be a large step in that direction - and to urge site owners to adopt HTTPS as soon as possible.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Opportunistic Encryption]]></title>
    <link href="https://adamcaudill.com//2014/02/25/on-opportunistic-encryption/"/>
    <updated>2014-02-25T14:51:00-05:00</updated>
    <id>https://adamcaudill.com//2014/02/25/on-opportunistic-encryption</id>
    <content type="html"><![CDATA[<p>Opportunistic encryption has become quite a hot topic recently, and blew up in a big way thanks to an <a href="https://en.wikipedia.org/wiki/Internet_Draft">Internet Draft</a> that was published on February 14th for what amounts to sanctioned man-in-the-middle. Privacy advocates were quickly up in arms - but it&#8217;s not that simple (<a href="http://tools.ietf.org/html/draft-loreto-httpbis-trusted-proxy20-01">see here</a>). As <a href="http://hillbrad.typepad.com/blog/2014/02/trusted-proxies-and-privacy-wolves.html">pointed out</a> by <a href="https://twitter.com/hillbrad">Brad Hill</a>, this isn&#8217;t about HTTP<strong>S</strong> traffic, but HTTP traffic using unauthenticated TLS; thanks to poor wording in the document, it&#8217;s easy to miss that fact if you just skim it.</p>

<p>It&#8217;s routine practice for ISPs to MITM unencrypted traffic today; it&#8217;s well known that <a href="https://blog.ryankearney.com/2013/01/comcast-caught-intercepting-and-altering-your-web-traffic/">Comcast does it</a>. This practice won&#8217;t change once we move to HTTP2, regardless of unauthenticated TLS - the only question is will users know about it.</p>

<p>But this isn&#8217;t about that single internet draft, it&#8217;s about what this tells us about opportunistic encryption.</p>

<p>We&#8217;ve seen many smart people get very upset (myself included) over a misunderstanding about how opportunistic encryption fits into the new HTTP2 paradigm. What does that tell us about how it&#8217;ll be perceived in the future?</p>

<p><strong>What does opportunistic encryption buy us?</strong></p>

<p>We can break attackers down into two classes:</p>

<ul>
<li>Active - Will intercept and re-route traffic, at small or large scale.</li>
<li>Passive - Will watch what goes over the wire, but is unable or unwilling to interfere with it.</li>
</ul>


<p>Opportunistic encryption prevents passive attackers from being able to collect data, they will either fail or be forced into an active role (if they are positioned and financed to do so). While many talk about increasing the cost of surveillance for groups like the NSA, I doubt that will create a substantial impact - we know that they are both active and passive today. So they are positioned for active attacks when they so desire, though there may be some reduction of monitoring lower value targets due to increased complexity / resource demands.</p>

<p><strong>What opportunistic encryption doesn&#8217;t do</strong></p>

<p>Unauthenticated TLS skips the most vital step in the process - it doesn&#8217;t verify that the server is actually the one you intend to talk to, meaning anyone that can control network traffic between you and the end server, can pretend to be the end server, monitoring all traffic. Which is, exactly what we have today with HTTP traffic.</p>

<p>So, you know your traffic is encrypted, what you don&#8217;t know is who has the keys, or how many people have seen the traffic. You&#8217;re safe from passive threats, but it provides no protection against active threats - but it&#8217;s also not intended to.</p>

<p><strong>Should we pursue it?</strong></p>

<p>If people weren&#8217;t involved - it eliminates a class of attacks without substantial costs, and forces passive attackers to become active. Overall, that sounds like a win, but there&#8217;s a problem: people.</p>

<p>Opportunistic encryption isn&#8217;t real security, it doesn&#8217;t stand up to active attackers - it provides protection against only a specific type of attack. Real TLS provides protection against both active and passive threats. If people understood this, opportunistic encryption would be fine - but people don&#8217;t understand that, that&#8217;s clear.</p>

<p>If people see it as a &#8220;just works&#8221; alternative to real TLS, then the harm it does greatly outweighs the value it provides. It will give a false sense of security, when in reality there is none.</p>
]]></content>
  </entry>
  
</feed>
