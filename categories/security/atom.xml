<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Security | Adam Caudill]]></title>
  <link href="https://adamcaudill.com//categories/security/atom.xml" rel="self"/>
  <link href="https://adamcaudill.com//"/>
  <updated>2015-08-06T21:33:01-04:00</updated>
  <id>https://adamcaudill.com//</id>
  <author>
    <name><![CDATA[Adam Caudill]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Poking Mykonos]]></title>
    <link href="https://adamcaudill.com//2012/01/23/poking-mykonos/"/>
    <updated>2012-01-23T22:28:56-05:00</updated>
    <id>https://adamcaudill.com//2012/01/23/poking-mykonos</id>
    <content type="html"><![CDATA[<p>While checking on the latest updates in the start-up world from TechCrunch, I came across <a href="http://techcrunch.com/2012/01/23/mykonos-helps-companies-battle-hackers-raises-4-million/">their article</a> on <a href="http://www.mykonossoftware.com/">Mykonos</a>; the important part of their article (at least for me), is this:</p>

<p><em>Mykonos’s Web Security product uses deception to “detect, confuse, slow down and prevent attackers” in real-time in order to help companies protect their websites and Web apps from malicious hacker and proactively prevent fraud and theft.</em></p>

<p>A couple of minutes of reading, and my interest was piqued - to say the least. The thing that most interested me was the claim of no false positives, while they do <a href="http://www.mykonossoftware.com/early-detection.php">talk about it</a> - I really wanted to see it for myself. Assuming they used their own product to protect their site, I took a few minutes to see what I could find - and find I did.</p>

<p>The first thing I did was a view-source to see what I could learn about their site - mainly to see if there were any obvious signs of using one CMS or another. The first thing that jumps out at me is this from the HTML:</p>

<pre><code>&lt;!-- InstanceBegin template="/Templates/mykonos.dwt.php"
     codeOutsideHTMLIsLocked="false" --&gt;
</code></pre>

<p>So, this tells us they are using Dreamweaver, and the name of the template. So, the next question is, does that <a href="http://www.mykonossoftware.com/Templates/"><code>/Templates/</code></a> directory exist on the server?</p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1930.png" alt="File Listing" /></p>

<p>Yup.</p>

<p>So, not only does it exist, they have directory listings turned on - which to me was a real shock. Unfortunately for us though, these files are named with the <code>.php</code> extension and not the <code>.dwt</code> I was hoping for, so we can't get much useful from them.</p>

<p>So, from looking at the source of the home page, we can see that the css files are stored in a <a href="http://www.mykonossoftware.com/css/">/css/</a> directory - maybe that'll be interesting.</p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1935.png" alt="File Listing" /></p>

<p>It's there, and like last time, we can see all of the files. While CSS files are of no real interest, the <a href="http://www.mykonossoftware.com/css/_notes/">/_notes/</a> directory is, because it'll contain a file called <code>dwsync.xml</code> - which can be quite interesting (since we knew they are using Dreamweaver, it's not too surprising to see this). This file contains data about the last time the site was pushed from Dreamweaver, and will contain one entry per file, and looks like this:</p>

<pre><code>&lt;file name="style.css"
 server="ftp.belincreative.com/public_html/clients/mykonos/site/"
 local="129651858311162109"
 remote="129651936600000000"/&gt;
</code></pre>

<p>The most interesting thing there is the <code>server</code> entry, as it tells us a little about the file-system; which if we were really trying to attack the site, knowing that would be handy. The other thing of interest is that when you see one <code>/_notes/</code> directory, you'll see lots more, as Dreamweaver likes to put them everywhere.</p>

<p>So, let's see if there's one in the root - that should be the most interesting one. Sure enough: <a href="http://www.mykonossoftware.com/_notes/">/_notes/</a></p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1949.png" alt="" /></p>

<p>This one has a few interesting entries, such as a <a href="http://www.mykonossoftware.com/TechSpecsWhatsNew.html">PHP file</a> that is named with an HTML extension - causing the code not to execute. Viewing the source of that file in the browser exposes the <a href="http://www.mykonossoftware.com/inc/">/inc/</a> directory; potentially interesting, but yields little information. The next file I tried (knowing it would be way too easy if it worked), was the <a href="http://www.mykonossoftware.com/.htaccess">.htaccess</a> file:</p>

<pre><code>&lt;files "webadmin.pl"&gt;
    AuthUserFile /usr/local/www/public_html/.htpasswd
    AuthType Basic
    AuthName "Server Administration"
    require valid-user
&lt;/files&gt;
</code></pre>

<p>Now, at first glance things look too good to be true - and that's because they are. Look at the path in <code>AuthUserFile</code> and compare that to the entries from the <code>dwsync.xml</code> files. This <code>.htaccess</code> file is part of the trap, which is all but confirmed if you try to go to the <a href="http://www.mykonossoftware.com/.htpasswd">.htpasswd</a> file which shouldn't work, since the path isn't what we would expect.</p>

<p>Now, while mucking around looking at the aforementioned files, and others such as <a href="http://www.mykonossoftware.com/robots.txt">robots.txt</a>, I would periodically see this, which I would assume is part of that "no false positive" promise:</p>

<p><img src="http://adamcaudill.com/files/2012-01-23_1716.png" alt="" /></p>

<p>I was hoping to run into the firewall (for lack of a better term) - looks like I got my wish; though since I wasn't using anything automated and was just poking around by hand, it didn't have any impact. Not terribly exciting, but it did provide some insight into what they are doing.</p>

<p>So far we've found a few interesting things, and bumped into their firewall, but that all pales in comparison to the last entry in the <code>dwsync.xml</code> file:</p>

<pre><code>&lt;file name="local-site.zip"
 server="ftp.belincreative.com/public_html/clients/mykonos/site/"
 local="129695851046591796"
 remote="129695888400000000"/&gt;
</code></pre>

<p>When I saw the file name I was shocked - could it really be? But I was right. It's a 59MB file containing everything on the site - all the PHP and everything else. Out of curiosity, I compared the <code>.htaccess</code> to that in the zip file, as expected it's quite different and more believable:</p>

<pre><code>Options +FollowSymlinks
RewriteEngine on
rewritecond %{http_host} ^mykonossoftware.com [nc]
rewriterule ^(.*)$ http://www.mykonossoftware.com/$1 [r=301,nc]
</code></pre>

<p>That confirms what I suspected, the file I saw earlier was just part of the trap.</p>

<p><strong>So what have we learned?</strong></p>

<p>1). Mykonos makes a really cool product, and had I not known what I was up against (and thus less skeptical about everything) it probably would have killed a lot of my time - just as intended.</p>

<p>2). No matter what you put in front or your site or application,<em> human mistakes are still your greatest risk</em>. A second set of eyes and a little paranoia go a long way in securing your systems, and stopping hackers.</p>

<p>3). Mykonos was either lucky or smart in that there was little on their site that shouldn't be seen by the public. If they were using a CMS with a database back-end instead of simple (mostly-)static pages, this could have been worse. If they had source code or other valuable IP on the server, a mistake like this could be devastating.</p>

<p>4). Mykonos should take some of their new-found cash and hire somebody to finish the audit of their site that I started. ;)</p>

<p><em>Note:</em> I notified Mykonos about that zip file before posting this (through a couple of channels), and I'm intentionally not linking to it. While I didn't see anything in there that would be an issue to be publicly disclosed, I'm sure they don't want it getting out. Hopefully by the time anybody reads this, they will have taken care of that file.</p>

<p><em><strong>Update:</strong></em> As expect, they've cleaned up the files I mentioned - and a bit more. In a <a href="http://twitter.com/#!/dkoretz/status/162033710202486786">tweet</a> from the company's CEO, <a href="http://www.davidkoretz.com/">David Koretz</a>, he mentioned that they had left a surprise for me. So I went to my starting point (the <code>/Templates/</code> directory), and was greeted with this:</p>

<p><img src="http://adamcaudill.com/files/2012-01-25_0005.png" alt="Welcome &amp; Thanks" /></p>

<p>Yeah, cool product and cool people. I'm impressed.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Chrome Leaking Credit Card Data?]]></title>
    <link href="https://adamcaudill.com//2012/01/15/google-chrome-leaking-credit-card-data/"/>
    <updated>2012-01-15T11:04:04-05:00</updated>
    <id>https://adamcaudill.com//2012/01/15/google-chrome-leaking-credit-card-data</id>
    <content type="html"><![CDATA[<p>While testing <a href="https://github.com/adamcaudill/ccsrch">ccsrch</a> I noticed a number that looked familiar - my debit card number. Now, being just a little paranoid, I don't leave such information on my system unencrypted - so seeing it was a real surprise. But, here's the real kicker: it was on my work PC, where it never should have been. But there it was, plain as day, in clear text. I spent a couple of minutes staring at the log trying to figure out why it would be there.</p>

<p>Once I saw the file name, a sinking feeling set in and the answer became clear:</p>

<p><code>%LocalAppData%\Google\Chrome\User Data\Default\Sync Data\SyncData.sqlite3</code></p>

<p>So it turns out that it's Chrome's <a href="http://support.google.com/chrome/bin/answer.py?hl=en&amp;answer=165139">sync</a> feature that was saving my information, but why?</p>

<p>It turns out that auto-fill data is synced with your Google account (if you're signed in and have the feature enable, of course), and all of the computers you're signed into - and by default, without the benefit of encryption. This file may contain any number of things, from mine I was able to extract the following:</p>

<ul>
<li><p>Full name</p></li>
<li><p>Wife's full name</p></li>
<li><p>Date of birth</p></li>
<li><p>Wife's date of birth</p></li>
<li><p>Social Security Number</p></li>
<li><p>Multiple credit card numbers</p></li>
<li><p>Multiple <a href="http://en.wikipedia.org/wiki/Card_security_code">CVV</a>s</p></li>
<li><p>Bank account &amp; routing number</p></li>
</ul>


<p>Not to mention quite a few websites I've been to, various addresses, employer's name and other various useful tidbits. All would be quite useful for identity theft or highly targeted <a href="http://www.fbi.gov/news/stories/2009/april/spearphishing_040109">spear phishing</a>.</p>

<p>Now am I saying that syncing auto-fill is bad? No, not at all. It's a very useful time saver, but what takes it from a useful feature to security issue is the fact that by default, this <em>data isn't encrypted</em>!</p>

<p><img src="http://adamcaudill.com/files/2012-01-15_0905.png" alt="Default Encryption Setting" /></p>

<p><strong>What are the risks?</strong></p>

<p>There are three significant risks I see here:</p>

<p>1). <em>Disclosure to less trusted systems</em>:</p>

<p>In my case, I trust my laptop to be secure; between full-disk encryption (via <a href="http://www.truecrypt.org/">TrueCrypt</a>) and other precautions, I know that I don't have too much to worry about. On the other hard, my Work PC is on a corporate domain, and at least a couple dozen people have permissions sufficient to access my personal files - thus I don't trust anything too valuable on it.</p>

<p>Now because of the fact that this feature is insecure by default, that data is exposed to a less trusted system.</p>

<p>It can also go the other way: a number of auto-fill entries on my personal laptop were from forms on internal-only applications that only my Work PC would be able to access. So this means that anything sensitive could be leaked to home networks which are typically less secure than corporate environments. If you routinely handle PCI, HIPAA, or other restricted information - this type of leak could be a major issue.</p>

<p>2). <em>Spear Phishing</em>:</p>

<p>Let's imagine a scenario:</p>

<p>You work for a defense contractor and I work for a foreign intelligence agency. Through some targeted attacks I manage to penetrate your home network, but have been unable to make it into your corporate network. I grab the sync database file from your home PC and extract one of your credit card numbers. I look up the <a href="http://en.wikipedia.org/wiki/List_of_Issuer_Identification_Numbers">IIN</a> and find out what bank the card is from. Once I have this, I build a PDF with the latest 0day exploit, and send it with a convincing subject line:</p>

<p>"Important Information about your Bank of America credit card ending in 7850"</p>

<p>Normally you'd dismiss it as spam, but the last four digits are right - so you open it, just in case. The exploit kicks in. I'm in, you're done.</p>

<p>This is just a simple and quite contrived example, but you get the idea.</p>

<p>3). <em>Google Data Mining</em>:</p>

<p>This is the most paranoid and least likely, but given Google's issues in controlling their people - I'd say not impossible (see <a href="http://www.electronista.com/articles/10/05/14/google.admits.collecting.wi.fi.info.with.map.team/">here</a>, <a href="http://searchengineland.com/google-chrome-page-will-have-pagerank-reduced-due-to-sponsored-posts-106551">here</a>, and <a href="http://boingboing.net/2012/01/13/google-fraudulently-solicits-f.html">here</a>).</p>

<p>Just for a moment, think about the fact that Google has the following:</p>

<ul>
<li><p>Your account data (name, email, etc.)</p></li>
<li><p>Your auto-fill history (see the list of items I found above)</p></li>
<li><p>Tons of data from their other services</p></li>
<li><p>At least parts of your browsing history, if not much of it</p></li>
<li><p>Engineers that truly enjoy data mining</p></li>
</ul>


<p>Most other companies I wouldn't worry about; but knowing the people that Google hires, and the skill they have in manipulating data - you know that some engineer is using his <a href="http://www.nytimes.com/2007/10/21/jobs/21pre.html">20% time</a> to do this (or at least is wishing he could).</p>

<p>If nothing else, I know if I worked at Google - playing with this data would be tons of fun. ;)</p>

<p><strong>Want to see your data?</strong></p>

<p>To see what Chrome has saved about you, download <a href="http://sqlitebrowser.sourceforge.net/">SQLite Browser</a>, and open the file I mentioned above. Go to the "Browse Data" tab, and select the "metas" table. What you're looking for is in the "non_unique_name" column (among other places). You should see something like this:</p>

<p><img src="http://adamcaudill.com/files/2012-01-15_0942.png" alt="SQLite Browser" /></p>

<p>The entries starting with "autofill_entry" are the ones you are interested in, but you'll likely find some of the other records interesting as well. If you see the word "encrypted" then your data is already encrypted, and you don't have to worry about this.</p>

<p><strong>Is this a vulnerability in Chrome?</strong></p>

<p>No, not at all - though it was a mistake. They should encrypt everything by default, and not provide an option to do otherwise. There's no reason to expose users to a potential security risk when there's a simple fix. Security isn't something users should have to opt-in to; and unless there's a very good reason, they shouldn't have a way to opt-out.</p>

<p>Google should understand security and the value of the data they hold; they should be more responsible for the data (and faith) people give them.</p>

<p><strong>How do I fix it?</strong></p>

<p>Simple, from the "wrench" menu, select Options -> Personal Stuff -> Sign In -> Advanced... and then under "Encrypted data types" select "Encrypt all synced data" - and that's it. After a couple of minutes the entries that were visible before will now just display the word "encrypted."</p>

<p><img src="http://adamcaudill.com/files/2012-01-15_0944.png" alt="Encrypt all data" /></p>

<p>You can also go a step further, and get rid of this data by disabling auto-fill to ensure that potentially sensitive information isn't being persisted when it shouldn't be.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CCSRCH v1.0.5]]></title>
    <link href="https://adamcaudill.com//2012/01/14/ccsrch-v1-0-5/"/>
    <updated>2012-01-14T08:08:39-05:00</updated>
    <id>https://adamcaudill.com//2012/01/14/ccsrch-v1-0-5</id>
    <content type="html"><![CDATA[<p>During my employers annual <a href="https://www.pcisecuritystandards.org/">PCI</a> audit, our auditor requested that we perform a search of all of our servers for credit card data. He recommended a tool called "ccsrch" - which like many open source projects had a couple of issues, and hadn't been updated in years. So, I fixed it.</p>

<p>CCSRCH is a cross-platform, command-line application that reads every file from the starting point passed in, and scans them for what looks like credit card numbers (and using the <a href="http://en.wikipedia.org/wiki/Luhn_algorithm">Luhn algorithm</a> to check each possible result). It's fairly brute-force, but it gets the scans required for PCI - though I would be careful about using it during production hours, it can have a pretty significant impact on a server's I/O performance.</p>

<p>I've forked the application and setup a new <a href="https://github.com/adamcaudill/ccsrch">ccsrch</a> project over at github (the original is on <a href="http://sourceforge.net/projects/ccsrch/">SourceForge</a>), and made a few modifications to better suit my needs (from the <a href="https://github.com/adamcaudill/ccsrch#readme">change log</a>):</p>

<ul>
<li><p>Added option to output the file name, and how many hits were found to the console when using -o (see -c in usage).</p></li>
<li><p>Added option to limit the number of results from a single file before going on to the next file (see -l in usage).</p></li>
<li><p>Added option to exclude certain file types from the scan (see -n in usage).</p></li>
<li><p>Fix for ignoring NULL, CR &amp; LF.</p></li>
<li><p>Ignore dash when scanning.</p></li>
<li><p>Exclude results with the last 8 digits repeating (very unlikely to be a real PAN).</p></li>
</ul>


<p>I've <a href="https://github.com/adamcaudill/ccsrch/downloads">uploaded</a> a Windows build of the new 1.0.5 release to github, and for *nix systems, you can just download the latest <a href="https://github.com/adamcaudill/ccsrch/tags">tag</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A brief look at the latest @LulzSec release]]></title>
    <link href="https://adamcaudill.com//2011/06/16/a-brief-look-at-the-latest-lulzsec-release/"/>
    <updated>2011-06-16T20:01:41-04:00</updated>
    <id>https://adamcaudill.com//2011/06/16/a-brief-look-at-the-latest-lulzsec-release</id>
    <content type="html"><![CDATA[<p>Earlier today, the hacker collective <a href="http://lulzsecurity.com/">Lulz Security</a> released a batch of 62,156 email/password combinations from unknown sites; I decided to take a look at the data and see if there was anything to be learned from it.</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet" align="center"><p>And as always, LulzSec delivers: <a href="http://t.co/yQlcu5x" title="http://www.mediafire.com/?9em5xp7r0rd2yod">mediafire.com/?9em5xp7r0rd2y…</a> 62,000+ emails/passwords just for you. Enjoy.</p>&mdash; The Lulz Boat (@LulzSec) <a href="https://twitter.com/LulzSec/status/81327464156119040">June 16, 2011</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>So, let's take a look at a few stats:</p>

<p>Total Domains: ~5,230</p>

<p>Top 15 Domains:</p>

<p><img src="http://adamcaudill.com/files/2011-06-16_1922.png" alt="Top 15 Domains" /></p>

<p>There are over 50,000 unique passwords, but even with this many passwords, there's still a few quite common - and very bad passwords in use:</p>

<p><img src="http://adamcaudill.com/files/2011-06-16_1936.png" alt="Top Passwords" /></p>

<p>While this is a fairly small release, the <a href="http://twitter.com/#!/LulzSec/">LulzSec</a> twitter stream has a number of entries like these:</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet" align="center"><p>There is some very angry level 85 WoW player cutting his wrists right now, thanks to @<a href="https://twitter.com/miraclejoe">miraclejoe</a> and LulzSec. Let it flow...</p>&mdash; The Lulz Boat (@LulzSec) <a href="https://twitter.com/LulzSec/status/81334551686815745">June 16, 2011</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>There are several tweets about people accessing Facebook, Twitter, and even Amazon accounts - what's so unfortunate here is that service providers could easily restrict accounts on lists like this to protect the users and greatly reduce the impact of these breaches.</p>

<p>Until people learn that password reuse is dangerous, this will keep happening.</p>

<p><em>Update:</em> I've removed a link to a tweet, as the account has since been removed. The tweet said: "@LulzSec Cheers for the paypal account with £250 in it! ;)"</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TED: Stuxnet: a preview of future wars]]></title>
    <link href="https://adamcaudill.com//2011/03/29/ted-stuxnet-a-preview-of-future-wars/"/>
    <updated>2011-03-29T19:28:29-04:00</updated>
    <id>https://adamcaudill.com//2011/03/29/ted-stuxnet-a-preview-of-future-wars</id>
    <content type="html"><![CDATA[<p><a href="http://www.langner.com/en/">Ralph Langner</a> recently spoke at TED about his team's findings on <a href="http://en.wikipedia.org/wiki/Stuxnet">Stuxnet</a>; it's a clear (and somewhat scary) insight into the wars of the future. Instead of sending fighters and bombers to take out <a href="http://articles.cnn.com/2010-09-29/world/iran.cyberattack_1_nuclear-program-bushehr-nuclear-plant-malware?_s=PM:WORLD">Iran's nuclear program</a>, as was done in 1981 to eliminate <a href="http://en.wikipedia.org/wiki/Operation_Opera">Iraq's program</a>, a carefully crafted virus slowly and methodologically damaged or destroyed vital equipment.</p>

<p>How long until this is used as a standard part of 'softening' a target by taking out key infrastructure (flight systems, power plants, telephone &amp; internet, etc.) before the bombs start to fly?</p>

<p>For those of us that have a professional interest in security, understanding the threats both present and future is simply a necessity.</p>

<p>This is a must watch.</p>

<p><video width='720' height='480' preload='none' controls poster=' http://images.ted.com/images/ted/tedindex/embed-posters/RalphLangner-2011.embed_thumbnail.jpg'><source src='http://download.ted.com/talks/RalphLangner_2011-480p.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/></video></p>

<p><a href="http://www.ted.com/talks/ralph_langner_cracking_stuxnet_a_21st_century_cyberweapon.html">Ralph Langner: Cracking Stuxnet, a 21st-century cyber weapon</a></p>

<p>Update: If you want to dig into some technical detail, <a href="http://blogs.technet.com/b/markrussinovich/archive/2011/03/30/3416253.aspx">Mark Russinovich</a> has a good write-up on it.</p>
]]></content>
  </entry>
  
</feed>
